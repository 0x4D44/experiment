# High-Level Design: AI-Powered Automated Trading System
## Interactive Brokers UK Integration

**Document Version:** 1.0
**Date:** November 13, 2025
**Target Platform:** Interactive Brokers (U.K.) Limited
**Regulatory Compliance:** FCA (Financial Conduct Authority)
**Status:** Design Phase

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Platform Selection Rationale](#platform-selection-rationale)
3. [System Overview](#system-overview)
4. [Architecture Design](#architecture-design)
5. [Component Design](#component-design)
6. [API Integration Strategy](#api-integration-strategy)
7. [Data Management Architecture](#data-management-architecture)
8. [AI/ML Integration](#aiml-integration)
9. [Security Design](#security-design)
10. [Risk Management Framework](#risk-management-framework)
11. [Deployment Strategy](#deployment-strategy)
12. [Monitoring & Observability](#monitoring--observability)
13. [Compliance & Regulatory](#compliance--regulatory)
14. [Disaster Recovery & Business Continuity](#disaster-recovery--business-continuity)
15. [Scalability & Performance](#scalability--performance)
16. [Technology Stack](#technology-stack)
17. [Development Roadmap](#development-roadmap)
18. [Cost Analysis](#cost-analysis)
19. [Risks & Mitigations](#risks--mitigations)
20. [Appendices](#appendices)

---

## Executive Summary

### Purpose

This High-Level Design document outlines the architecture and implementation strategy for an AI-powered automated trading system targeting UK residents, utilizing Interactive Brokers UK as the primary brokerage platform.

### Objectives

1. **Automated Trading:** Enable fully automated trade execution based on AI-generated signals
2. **Low-Cost Operation:** Minimize trading costs and infrastructure expenses
3. **Regulatory Compliance:** Ensure FCA compliance for UK operations
4. **Risk Management:** Implement robust risk controls and position sizing
5. **High Reliability:** Target 99.9% uptime for trading operations
6. **Scalability:** Support multiple trading strategies and asset classes

### Key Features

- Real-time market data ingestion and processing
- AI/ML-driven signal generation
- Automated order placement and management
- Multi-asset support (stocks, options, futures, forex)
- Real-time portfolio monitoring and risk assessment
- Comprehensive logging and audit trails
- Web-based dashboard for monitoring and control

### Success Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| System Uptime | 99.9% | Monthly availability |
| Order Execution Latency | < 500ms | 95th percentile |
| API Response Time | < 100ms | Average |
| Data Processing Delay | < 1 second | Real-time feeds |
| Strategy Backtesting Time | < 5 minutes | Per strategy |
| Maximum Daily Loss | < 2% of portfolio | Risk management |

---

## Platform Selection Rationale

### Selected Platform: Interactive Brokers (U.K.) Limited

**Decision:** Interactive Brokers UK has been selected as the most promising candidate for UK-based automated trading operations.

### Key Selection Criteria

#### 1. Regulatory Compliance ✓
- **FCA Authorization:** FCA Reference Number **208159**
- **Entity:** Interactive Brokers (U.K.) Limited
- **Investor Protection:** FSCS protection up to £85,000
- **Regulatory Status:** Fully authorized and regulated

#### 2. API Capabilities ✓
- **TWS API:** Mature, feature-rich, asynchronous API
- **Client Portal API:** RESTful web API for account management
- **Multiple Languages:** Python, Java, C++, C#
- **High Performance:** Up to 50 orders per second
- **Real-time Data:** Streaming market data via WebSocket

#### 3. Market Access ✓
- **Global Coverage:** 150+ markets across 33 countries
- **Asset Classes:** Stocks, options, futures, forex, bonds, funds, CFDs
- **UK Markets:** Full access to LSE, AIM, and other UK exchanges
- **US Markets:** NYSE, NASDAQ, AMEX
- **European Markets:** XETRA, Euronext, SIX Swiss Exchange

#### 4. Cost Structure ✓
- **Low Commissions:** $0.0005-$0.0035 per share (IBKR Pro)
- **Volume Discounts:** Lower rates for high-volume trading
- **API Access:** Free with account
- **Market Data:** Competitive subscription fees
- **No Platform Fees:** No monthly platform charges

#### 5. Infrastructure ✓
- **Proven Reliability:** Established since 1978
- **Institutional Grade:** Used by professional traders and hedge funds
- **High Volume Capacity:** Handles millions of trades daily
- **Advanced Technology:** Cutting-edge execution systems
- **Global Presence:** Offices and data centers worldwide

#### 6. Track Record ✓
- **Reputation:** Highly trusted in the industry
- **Financial Strength:** Publicly traded (NASDAQ: IBKR)
- **Algo Trading Focus:** Designed for algorithmic trading
- **Community:** Large developer community and resources

### Comparison with Alternatives

| Platform | FCA Reg | API Quality | Markets | Cost | UK Suitability | Score |
|----------|---------|-------------|---------|------|----------------|-------|
| **Interactive Brokers UK** | ✓ | Excellent | 150+ | Low | Excellent | 9.5/10 |
| Alpaca | ✗ | Excellent | US only | Free | Limited | 6.5/10 |
| Pepperstone UK | ✓ | Good (MT4) | Forex/CFD | Low | Good | 7.0/10 |
| IG Markets UK | ✓ | Limited | CFD focus | Medium | Good | 6.5/10 |
| Saxo Markets UK | ✓ | Good | Global | High | Good | 7.5/10 |

**Winner:** Interactive Brokers UK provides the optimal combination of regulatory compliance, API capabilities, market access, and cost-effectiveness for UK-based automated trading.

---

## System Overview

### High-Level System Description

The AI-Powered Automated Trading System is a distributed, event-driven architecture that ingests real-time market data, processes it through AI/ML models, generates trading signals, executes trades via Interactive Brokers API, and monitors portfolio performance with comprehensive risk management.

### System Context Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│                    External Environment                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌──────────────┐         ┌─────────────────────────────┐       │
│  │              │         │  Interactive Brokers UK      │       │
│  │  Market Data │◄────────┤  - TWS API (Trading)        │       │
│  │  Providers   │         │  - IB Gateway               │       │
│  │  (FMP, etc.) │         │  - Real-time Market Data    │       │
│  │              │         │  - Order Execution          │       │
│  └──────────────┘         └─────────────────────────────┘       │
│         │                              ▲                          │
│         │                              │                          │
│         ▼                              │                          │
│  ═══════════════════════════════════════════════════════════     │
│  ║           AI Automated Trading System               ║         │
│  ║                                                      ║         │
│  ║  ┌───────────────┐  ┌──────────────┐  ┌─────────┐ ║         │
│  ║  │ Data          │  │ AI/ML        │  │ Trading │ ║         │
│  ║  │ Ingestion     │─►│ Engine       │─►│ Engine  │ ║         │
│  ║  └───────────────┘  └──────────────┘  └─────────┘ ║         │
│  ║          │                  │              │        ║         │
│  ║          ▼                  ▼              ▼        ║         │
│  ║  ┌───────────────┐  ┌──────────────┐  ┌─────────┐ ║         │
│  ║  │ Data          │  │ Strategy     │  │ Risk    │ ║         │
│  ║  │ Storage       │  │ Manager      │  │ Manager │ ║         │
│  ║  └───────────────┘  └──────────────┘  └─────────┘ ║         │
│  ║          │                  │              │        ║         │
│  ║          └──────────────────┴──────────────┘        ║         │
│  ║                         │                            ║         │
│  ║                         ▼                            ║         │
│  ║              ┌────────────────────┐                  ║         │
│  ║              │ Monitoring &       │                  ║         │
│  ║              │ Dashboard          │                  ║         │
│  ║              └────────────────────┘                  ║         │
│  ═══════════════════════════════════════════════════════         │
│                                                                   │
│  ┌──────────────┐         ┌─────────────────────────────┐       │
│  │              │         │  Alerting & Notifications   │       │
│  │  Users       │◄────────┤  - Email                    │       │
│  │  (Operators) │         │  - SMS                      │       │
│  │              │         │  - Slack/Discord            │       │
│  └──────────────┘         └─────────────────────────────┘       │
│                                                                   │
└─────────────────────────────────────────────────────────────────┘
```

### Key Capabilities

1. **Data Ingestion**
   - Real-time market data streaming
   - Historical data retrieval and caching
   - Alternative data integration (news, sentiment)
   - Multi-source data aggregation

2. **AI/ML Processing**
   - Feature engineering and transformation
   - Signal generation via ML models
   - Backtesting and strategy validation
   - Model training and retraining pipeline

3. **Trading Execution**
   - Order placement and management
   - Position tracking and monitoring
   - Order routing and optimization
   - Execution quality analysis

4. **Risk Management**
   - Real-time position monitoring
   - Pre-trade risk checks
   - Portfolio-level risk limits
   - Drawdown protection
   - Stop-loss management

5. **Monitoring & Control**
   - Real-time dashboard
   - Performance analytics
   - System health monitoring
   - Manual intervention capabilities

---

## Architecture Design

### Overall Architecture Pattern

**Pattern:** Event-Driven Microservices Architecture with CQRS (Command Query Responsibility Segregation)

**Rationale:**
- **Event-Driven:** Market data and trading are inherently event-driven
- **Microservices:** Enables independent scaling and deployment
- **CQRS:** Separates read (market data, analytics) from write (order execution) concerns
- **Loose Coupling:** Components communicate via message queue
- **Resilience:** Failure in one component doesn't cascade

### Architectural Layers

```
┌─────────────────────────────────────────────────────────────────┐
│                      Presentation Layer                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ Web Dashboard│  │ REST API     │  │ Admin Panel  │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                      Application Layer                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ Trading      │  │ Strategy     │  │ Risk         │          │
│  │ Orchestrator │  │ Executor     │  │ Controller   │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                      Core Services Layer                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ Market Data  │  │ AI/ML        │  │ Order        │          │
│  │ Service      │  │ Service      │  │ Service      │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ Portfolio    │  │ Position     │  │ Analytics    │          │
│  │ Service      │  │ Service      │  │ Service      │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                      Integration Layer                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ IBKR TWS API │  │ Market Data  │  │ Notification │          │
│  │ Adapter      │  │ API Adapter  │  │ Gateway      │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                      Data Layer                                  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ PostgreSQL   │  │ TimescaleDB  │  │ Redis Cache  │          │
│  │ (Relational) │  │ (Time-Series)│  │              │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
│  ┌──────────────┐  ┌──────────────┐                             │
│  │ S3/MinIO     │  │ ClickHouse   │                             │
│  │ (Blob Store) │  │ (Analytics)  │                             │
│  └──────────────┘  └──────────────┘                             │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                      Infrastructure Layer                        │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │ Message      │  │ Monitoring   │  │ Service      │          │
│  │ Queue (NATS) │  │ (Prometheus) │  │ Mesh         │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
└─────────────────────────────────────────────────────────────────┘
```

### Component Interaction Flow

#### 1. Market Data Flow

```
Market Data Provider (FMP)
          │
          ▼
   [Market Data Adapter]
          │
          ▼
   [Message Queue: market.data.quotes]
          │
          ├──────────────┬──────────────┬──────────────┐
          ▼              ▼              ▼              ▼
   [Data Storage]  [AI/ML Service] [Analytics]  [Dashboard]
```

#### 2. Trading Signal Flow

```
Market Data + Historical Data
          │
          ▼
   [AI/ML Engine]
          │
          ▼
   [Signal Generated]
          │
          ▼
   [Message Queue: trading.signals]
          │
          ▼
   [Strategy Executor]
          │
          ▼
   [Risk Pre-Check]
          │
          ├─── PASS ───►[Order Service]───►[IBKR API]───►[Execution]
          │
          └─── FAIL ───►[Alert Service]───►[Notification]
```

#### 3. Order Execution Flow

```
[Order Request]
          │
          ▼
   [Pre-Trade Risk Checks]
          │
          ├─── Position Limits OK?
          ├─── Portfolio Exposure OK?
          ├─── Daily Loss Limit OK?
          ├─── Strategy Allocation OK?
          │
          ▼
   [Order Validation]
          │
          ▼
   [IBKR TWS API]
          │
          ▼
   [IB Gateway] ──► [Interactive Brokers UK]
          │
          ▼
   [Order Acknowledgement]
          │
          ├──► [Position Service Update]
          ├──► [Portfolio Service Update]
          ├──► [Analytics Service]
          └──► [Dashboard Update]
```

### Message Queue Architecture

**Technology:** NATS (high-performance messaging system)

**Key Topics:**

| Topic | Purpose | Subscribers |
|-------|---------|-------------|
| `market.data.quotes` | Real-time price quotes | AI/ML Service, Analytics, Dashboard |
| `market.data.trades` | Trade tick data | Analytics, Data Storage |
| `market.data.bars` | OHLCV bar data | AI/ML Service, Data Storage |
| `trading.signals` | AI-generated signals | Strategy Executor |
| `trading.orders.new` | New order requests | Order Service |
| `trading.orders.executed` | Order executions | Position Service, Portfolio Service |
| `trading.orders.cancelled` | Order cancellations | Position Service, Dashboard |
| `risk.alerts` | Risk limit breaches | Risk Manager, Notification Service |
| `system.health` | System health checks | Monitoring Service |
| `ibkr.events` | IBKR API events | All trading services |

### State Management

**Distributed State:** Redis Cluster

**State Types:**
1. **Session State:** IBKR API connection status, authentication tokens
2. **Order State:** Active orders, pending orders, order history (recent)
3. **Position State:** Current positions, unrealized P&L
4. **Risk State:** Current exposure, daily loss counter, limit breaches
5. **Strategy State:** Active strategies, strategy parameters
6. **Cache:** Market data cache, reference data cache

---

## Component Design

### 1. Market Data Service

**Responsibility:** Ingest, normalize, and distribute market data from multiple sources.

**Key Functions:**
- Connect to market data APIs (Financial Modeling Prep, IBKR market data)
- Subscribe to real-time price feeds
- Normalize data across different providers
- Publish to message queue
- Cache recent data in Redis
- Store historical data in TimescaleDB

**Technology Stack:**
- Language: Python 3.11+
- Framework: FastAPI (for REST endpoints)
- WebSocket: aiohttp for async connections
- Message Queue: NATS Python client

**Configuration:**
```yaml
market_data:
  providers:
    - name: fmp
      api_key: ${FMP_API_KEY}
      endpoints:
        realtime: wss://financialmodelingprep.com/v3/quote
        historical: https://financialmodelingprep.com/v3/historical-price
      rate_limit: 1000/min
    - name: ibkr
      connection: tws_api
      market_data_types: [REALTIME, DELAYED, FROZEN]

  symbols:
    - AAPL
    - MSFT
    - GOOGL
    # ... list of symbols

  cache:
    redis_ttl: 60  # seconds
    max_cache_size: 10000
```

**API Endpoints:**
- `GET /api/v1/market-data/quote/{symbol}` - Get latest quote
- `GET /api/v1/market-data/historical/{symbol}` - Get historical data
- `GET /api/v1/market-data/symbols` - List tracked symbols
- `POST /api/v1/market-data/subscribe` - Subscribe to symbols
- `DELETE /api/v1/market-data/unsubscribe` - Unsubscribe from symbols

**Data Model:**
```python
@dataclass
class Quote:
    symbol: str
    timestamp: datetime
    bid: Decimal
    ask: Decimal
    last: Decimal
    volume: int
    bid_size: int
    ask_size: int
    exchange: str
    source: str  # 'fmp', 'ibkr'
```

---

### 2. AI/ML Service

**Responsibility:** Generate trading signals using machine learning models.

**Key Functions:**
- Load and manage ML models
- Feature engineering from market data
- Real-time signal generation
- Model backtesting
- Model retraining pipeline
- A/B testing of models

**Technology Stack:**
- Language: Python 3.11+
- ML Framework: PyTorch, scikit-learn
- Feature Store: Redis + PostgreSQL
- Model Registry: MLflow
- Inference: ONNX Runtime for production

**Architecture:**
```
┌────────────────────────────────────────────┐
│         AI/ML Service                       │
├────────────────────────────────────────────┤
│                                             │
│  ┌──────────────────────────────────────┐  │
│  │  Feature Engineering Pipeline        │  │
│  │  - Technical indicators              │  │
│  │  - Statistical features              │  │
│  │  - Alternative data integration      │  │
│  └──────────────────────────────────────┘  │
│                    │                        │
│                    ▼                        │
│  ┌──────────────────────────────────────┐  │
│  │  Model Inference Engine              │  │
│  │  - ONNX Runtime                      │  │
│  │  - Multi-model ensemble              │  │
│  │  - Real-time scoring                 │  │
│  └──────────────────────────────────────┘  │
│                    │                        │
│                    ▼                        │
│  ┌──────────────────────────────────────┐  │
│  │  Signal Generator                    │  │
│  │  - BUY / SELL / HOLD                 │  │
│  │  - Confidence score                  │  │
│  │  - Position sizing recommendation    │  │
│  └──────────────────────────────────────┘  │
│                    │                        │
│                    ▼                        │
│  ┌──────────────────────────────────────┐  │
│  │  Signal Publisher                    │  │
│  │  - Publish to message queue          │  │
│  │  - Log to database                   │  │
│  └──────────────────────────────────────┘  │
│                                             │
└────────────────────────────────────────────┘
```

**Model Pipeline:**

1. **Feature Engineering:**
   - Technical indicators (RSI, MACD, Bollinger Bands, etc.)
   - Price momentum features
   - Volume profile analysis
   - Market microstructure features
   - Cross-asset correlations
   - Alternative data (news sentiment, social media)

2. **Model Types:**
   - **Classification Models:** Predict direction (up/down/neutral)
   - **Regression Models:** Predict returns
   - **Time Series Models:** LSTM, Transformer for sequence prediction
   - **Ensemble Models:** Combine multiple models

3. **Model Evaluation:**
   - Sharpe Ratio
   - Maximum Drawdown
   - Win Rate
   - Profit Factor
   - Sortino Ratio

**Signal Data Model:**
```python
@dataclass
class TradingSignal:
    signal_id: str  # UUID
    timestamp: datetime
    symbol: str
    action: str  # 'BUY', 'SELL', 'HOLD'
    confidence: float  # 0.0 to 1.0
    model_name: str
    model_version: str
    features: Dict[str, float]
    predicted_return: Optional[float]
    predicted_risk: Optional[float]
    position_size_pct: float  # Percentage of portfolio
    stop_loss: Optional[Decimal]
    take_profit: Optional[Decimal]
    ttl: int  # Time-to-live in seconds
```

**Configuration:**
```yaml
ai_ml:
  models:
    - name: lstm_momentum
      version: v1.2.3
      path: models/lstm_momentum.onnx
      enabled: true
      weight: 0.4
    - name: random_forest_classifier
      version: v2.1.0
      path: models/rf_classifier.onnx
      enabled: true
      weight: 0.3
    - name: transformer_returns
      version: v1.0.5
      path: models/transformer.onnx
      enabled: true
      weight: 0.3

  ensemble:
    method: weighted_average
    min_confidence: 0.6  # Only generate signal if confidence > 0.6

  backtesting:
    enabled: true
    lookback_days: 365
    validation_split: 0.2
```

---

### 3. Order Service

**Responsibility:** Manage order lifecycle and interact with IBKR API.

**Key Functions:**
- Receive order requests from strategy executor
- Perform pre-trade risk checks
- Submit orders to IBKR via TWS API
- Track order status
- Handle order modifications and cancellations
- Manage order routing
- Record order history

**Technology Stack:**
- Language: Python 3.11+
- IBKR Integration: ibapi (Interactive Brokers Python API)
- Database: PostgreSQL (order history)
- Cache: Redis (active orders)

**Order State Machine:**
```
[NEW] ──► [VALIDATING] ──► [RISK_CHECK] ──┐
                                           │
                    ┌──────────────────────┘
                    │
                    ├──► [APPROVED] ──► [SUBMITTED] ──► [IBKR]
                    │                                     │
                    │                    ┌────────────────┤
                    │                    │                │
                    │                    ▼                ▼
                    │              [PENDING_SUBMIT] [SUBMITTED_TO_IB]
                    │                    │                │
                    │                    ▼                │
                    │              [PRE_SUBMITTED]        │
                    │                    │                │
                    │                    ├────────────────┘
                    │                    │
                    │                    ▼
                    │              [PENDING_CANCEL]
                    │                    │
                    │                    ├──► [CANCELLED]
                    │                    │
                    │                    ▼
                    │              [FILLED] ──► [CONFIRMED]
                    │
                    └──► [REJECTED]
```

**Order Types Supported:**
- Market Order
- Limit Order
- Stop Order
- Stop-Limit Order
- Trailing Stop
- TWAP (Time-Weighted Average Price)
- VWAP (Volume-Weighted Average Price)
- Adaptive Algo

**Order Data Model:**
```python
@dataclass
class Order:
    order_id: str  # Internal UUID
    ib_order_id: Optional[int]  # IBKR order ID
    symbol: str
    action: str  # 'BUY', 'SELL'
    order_type: str  # 'MARKET', 'LIMIT', etc.
    quantity: int
    limit_price: Optional[Decimal]
    stop_price: Optional[Decimal]
    time_in_force: str  # 'DAY', 'GTC', 'IOC', 'FOK'
    status: str
    created_at: datetime
    submitted_at: Optional[datetime]
    filled_at: Optional[datetime]
    filled_quantity: int
    filled_avg_price: Optional[Decimal]
    commission: Optional[Decimal]
    strategy_id: str
    signal_id: str
    account: str
```

**API Endpoints:**
- `POST /api/v1/orders` - Create new order
- `GET /api/v1/orders/{order_id}` - Get order status
- `GET /api/v1/orders` - List orders (with filters)
- `PUT /api/v1/orders/{order_id}` - Modify order
- `DELETE /api/v1/orders/{order_id}` - Cancel order
- `GET /api/v1/orders/{order_id}/executions` - Get order executions

---

### 4. Position Service

**Responsibility:** Track and manage portfolio positions.

**Key Functions:**
- Maintain real-time position data
- Calculate unrealized P&L
- Track cost basis and realized P&L
- Position reconciliation with IBKR
- Position reporting

**Technology Stack:**
- Language: Python 3.11+
- Database: PostgreSQL (position history)
- Cache: Redis (current positions)

**Position Data Model:**
```python
@dataclass
class Position:
    symbol: str
    account: str
    quantity: int  # Positive for long, negative for short
    avg_cost: Decimal
    current_price: Decimal
    market_value: Decimal
    unrealized_pnl: Decimal
    unrealized_pnl_pct: Decimal
    realized_pnl: Decimal
    last_updated: datetime
```

**API Endpoints:**
- `GET /api/v1/positions` - List all positions
- `GET /api/v1/positions/{symbol}` - Get position for symbol
- `GET /api/v1/positions/summary` - Portfolio summary
- `POST /api/v1/positions/reconcile` - Reconcile with IBKR

---

### 5. Risk Manager Service

**Responsibility:** Enforce risk limits and protect capital.

**Key Functions:**
- Pre-trade risk checks
- Real-time position monitoring
- Portfolio-level risk limits
- Drawdown protection
- Automatic position closure on limit breach
- Risk reporting

**Technology Stack:**
- Language: Python 3.11+
- Cache: Redis (risk state)
- Database: PostgreSQL (risk events)

**Risk Checks:**

1. **Pre-Trade Checks:**
   - Maximum position size per symbol
   - Maximum portfolio concentration
   - Maximum leverage
   - Maximum order size
   - Daily order count limit

2. **Portfolio Checks:**
   - Maximum daily loss ($ and %)
   - Maximum drawdown from peak
   - Maximum portfolio exposure
   - Sector/industry concentration limits

3. **Position Checks:**
   - Stop-loss enforcement
   - Take-profit targets
   - Position holding period limits
   - Correlation limits

**Risk Configuration:**
```yaml
risk_management:
  portfolio:
    max_daily_loss_pct: 2.0  # 2% of portfolio value
    max_daily_loss_usd: 10000
    max_drawdown_pct: 10.0
    max_leverage: 1.0  # No leverage

  position:
    max_position_size_pct: 5.0  # 5% of portfolio per position
    max_concentration_sector: 20.0  # 20% per sector
    max_correlated_exposure: 30.0  # Max 30% in correlated positions

  order:
    max_order_size_usd: 50000
    max_orders_per_day: 100
    max_orders_per_minute: 10

  stop_loss:
    default_stop_loss_pct: 3.0  # 3% stop loss
    trailing_stop_enabled: true
    trailing_stop_pct: 2.0
```

**Risk Alert Data Model:**
```python
@dataclass
class RiskAlert:
    alert_id: str
    timestamp: datetime
    severity: str  # 'WARNING', 'CRITICAL'
    alert_type: str  # 'DAILY_LOSS', 'POSITION_SIZE', 'DRAWDOWN'
    message: str
    current_value: Decimal
    limit_value: Decimal
    action_taken: str  # 'NONE', 'ORDER_REJECTED', 'POSITIONS_CLOSED'
```

---

### 6. Strategy Executor Service

**Responsibility:** Execute trading strategies based on AI signals.

**Key Functions:**
- Subscribe to trading signals
- Apply strategy rules and filters
- Calculate position sizing
- Generate order requests
- Manage strategy state
- Track strategy performance

**Strategy Types:**

1. **Momentum Strategy:**
   - Follow strong trends
   - Enter on signal confirmation
   - Trail stop-loss

2. **Mean Reversion Strategy:**
   - Identify overbought/oversold conditions
   - Enter on reversal signal
   - Fixed profit target

3. **Breakout Strategy:**
   - Identify key resistance/support levels
   - Enter on breakout confirmation
   - Volume-based validation

4. **Multi-Strategy Portfolio:**
   - Run multiple strategies simultaneously
   - Allocate capital across strategies
   - Rebalance periodically

**Strategy Configuration:**
```yaml
strategies:
  - id: momentum_long_only
    name: "Momentum Long Only"
    enabled: true
    capital_allocation: 0.4  # 40% of portfolio

    filters:
      min_confidence: 0.7
      min_liquidity: 1000000  # $1M daily volume
      max_spread_bps: 10  # 10 basis points

    position_sizing:
      method: kelly_criterion
      max_position_size_pct: 5.0

    risk:
      stop_loss_pct: 3.0
      take_profit_pct: 10.0
      max_holding_period_days: 10
```

---

### 7. IBKR API Adapter

**Responsibility:** Encapsulate all interactions with Interactive Brokers TWS API.

**Key Functions:**
- Maintain connection to IB Gateway
- Handle authentication and connection management
- Implement TWS API callback handlers (EWrapper)
- Provide simplified async interface for other services
- Handle reconnection logic
- Rate limiting

**Technology Stack:**
- Language: Python 3.11+
- Library: ibapi (Interactive Brokers official Python API)
- Connection: IB Gateway (preferred) or TWS

**Architecture:**

```python
class IBKRAdapter:
    """
    Adapter for Interactive Brokers TWS API
    """

    def __init__(self, config: IBKRConfig):
        self.client = EClient(self)
        self.wrapper = CustomEWrapper()
        self.connection_state = ConnectionState.DISCONNECTED

    async def connect(self):
        """Connect to IB Gateway"""

    async def disconnect(self):
        """Disconnect from IB Gateway"""

    async def place_order(self, order: Order) -> str:
        """Place order and return order ID"""

    async def cancel_order(self, order_id: str):
        """Cancel order"""

    async def get_positions(self) -> List[Position]:
        """Get current positions"""

    async def get_account_summary(self) -> AccountSummary:
        """Get account summary"""

    async def subscribe_market_data(self, symbols: List[str]):
        """Subscribe to real-time market data"""

    async def get_historical_data(
        self,
        symbol: str,
        duration: str,
        bar_size: str
    ) -> pd.DataFrame:
        """Get historical bar data"""
```

**Connection Management:**

```yaml
ibkr:
  connection:
    host: localhost
    port: 4001  # IB Gateway paper trading port
    client_id: 1

  authentication:
    username: ${IBKR_USERNAME}
    # IB Gateway handles authentication via login screen

  reconnection:
    max_retries: 10
    retry_interval: 30  # seconds
    exponential_backoff: true

  rate_limiting:
    max_requests_per_second: 40  # Stay under 50/sec limit
```

**Note on IB Gateway vs TWS:**
- **IB Gateway:** Lightweight, headless, can run indefinitely
- **TWS:** Full GUI, requires restart every 24 hours
- **Recommendation:** Use IB Gateway for production automated trading

---

### 8. Monitoring & Dashboard Service

**Responsibility:** Provide real-time visibility into system health and trading performance.

**Key Functions:**
- Real-time metrics collection
- Performance analytics
- System health monitoring
- Web-based dashboard
- Alerting and notifications

**Technology Stack:**
- Backend: Python FastAPI
- Frontend: React + TypeScript
- Metrics: Prometheus
- Visualization: Grafana
- Time-series: TimescaleDB

**Dashboard Features:**

1. **Trading Overview:**
   - Current positions
   - Today's P&L
   - Open orders
   - Recent executions

2. **Performance Metrics:**
   - Cumulative returns
   - Sharpe ratio
   - Maximum drawdown
   - Win rate
   - Profit factor

3. **Risk Metrics:**
   - Portfolio exposure
   - Sector concentration
   - Current drawdown
   - Risk limit utilization

4. **System Health:**
   - Service status
   - API connection status
   - Message queue depth
   - Latency metrics
   - Error rates

5. **Strategy Performance:**
   - Per-strategy P&L
   - Signal accuracy
   - Strategy allocation

**Alerting Rules:**
```yaml
alerts:
  - name: daily_loss_limit
    condition: daily_pnl < -2%
    severity: critical
    channels: [email, sms]

  - name: position_size_breach
    condition: position_size > 5%
    severity: warning
    channels: [email]

  - name: api_disconnection
    condition: ibkr_connection == false
    severity: critical
    channels: [email, sms, slack]

  - name: high_error_rate
    condition: error_rate > 5%
    severity: warning
    channels: [slack]
```

---

## API Integration Strategy

### Interactive Brokers TWS API Integration

#### Connection Architecture

**Client Software:** IB Gateway (recommended for production)

**Connection Flow:**
```
[Trading System] ──TCP Socket──► [IB Gateway] ──Internet──► [IBKR Servers]
     (Python)      (Port 4001)    (Localhost)               (Cloud)
```

**Configuration:**

1. **IB Gateway Setup:**
   - Download IB Gateway from IBKR website
   - Configure for automated login (optional, requires careful security)
   - Enable API connections
   - Set port: 4001 (paper), 4002 (live)
   - Disable "Read-Only API" for trading
   - Note: Socket port typically 7496 for TWS, 4001 for Gateway

2. **API Configuration:**
```python
# config/ibkr.yaml
ibkr:
  gateway:
    host: "127.0.0.1"
    port: 4001  # Paper trading
    client_id: 1

  connection:
    timeout: 30
    keepalive: true
    keepalive_interval: 60

  order_management:
    order_id_offset: 1000  # Start order IDs from 1000
    auto_increment: true
```

#### API Methods Used

**Account & Portfolio:**
- `reqAccountSummary()` - Get account balance, buying power
- `reqPositions()` - Get current positions
- `reqPnL()` - Get real-time P&L updates

**Market Data:**
- `reqMarketDataType()` - Set market data type (real-time, delayed, frozen)
- `reqMktData()` - Subscribe to real-time quotes
- `reqHistoricalData()` - Get historical bars
- `cancelMktData()` - Unsubscribe from market data

**Order Management:**
- `placeOrder()` - Submit order
- `cancelOrder()` - Cancel order
- `reqOpenOrders()` - Get open orders
- `reqExecutions()` - Get execution history

**Contract Details:**
- `reqContractDetails()` - Get contract specifications
- `reqSecDefOptParams()` - Get option parameters

#### Async Event Handling

TWS API is asynchronous - responses come via callback methods in `EWrapper`.

**Implementation Pattern:**

```python
from ibapi.client import EClient
from ibapi.wrapper import EWrapper
from ibapi.contract import Contract
from ibapi.order import Order
import asyncio
from typing import Dict
import threading

class IBKRWrapper(EWrapper):
    """Custom EWrapper implementation"""

    def __init__(self):
        EWrapper.__init__(self)
        self.order_responses: Dict[int, asyncio.Future] = {}
        self.position_data = []

    def orderStatus(self, orderId, status, filled, remaining,
                   avgFillPrice, permId, parentId, lastFillPrice,
                   clientId, whyHeld, mktCapPrice):
        """Callback when order status changes"""
        if orderId in self.order_responses:
            future = self.order_responses[orderId]
            future.set_result({
                'status': status,
                'filled': filled,
                'avg_price': avgFillPrice
            })

    def position(self, account, contract, position, avgCost):
        """Callback for position data"""
        self.position_data.append({
            'symbol': contract.symbol,
            'position': position,
            'avg_cost': avgCost
        })

class IBKRClient(EClient):
    """Custom EClient implementation"""

    def __init__(self, wrapper):
        EClient.__init__(self, wrapper)

class IBKRAsyncAdapter:
    """Async adapter for IBKR API"""

    def __init__(self):
        self.wrapper = IBKRWrapper()
        self.client = IBKRClient(self.wrapper)
        self.next_order_id = 1

    def connect(self, host: str, port: int, client_id: int):
        """Connect to IB Gateway"""
        self.client.connect(host, port, client_id)

        # Start message processing thread
        thread = threading.Thread(target=self.client.run, daemon=True)
        thread.start()

    async def place_order_async(self, contract: Contract,
                                order: Order) -> Dict:
        """Place order and wait for response"""
        order_id = self.next_order_id
        self.next_order_id += 1

        # Create future for response
        future = asyncio.Future()
        self.wrapper.order_responses[order_id] = future

        # Submit order
        self.client.placeOrder(order_id, contract, order)

        # Wait for response (with timeout)
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            return result
        except asyncio.TimeoutError:
            raise Exception(f"Order {order_id} timeout")
```

#### Rate Limiting

**IBKR Rate Limits:**
- 50 orders per second per connection
- Message rate limits vary by message type
- Market data subscription limits based on account type

**Implementation:**
```python
import asyncio
from collections import deque
from datetime import datetime, timedelta

class RateLimiter:
    """Token bucket rate limiter"""

    def __init__(self, max_calls: int, period: float):
        self.max_calls = max_calls
        self.period = period
        self.calls = deque()
        self.lock = asyncio.Lock()

    async def acquire(self):
        """Acquire permission to make API call"""
        async with self.lock:
            now = datetime.now()

            # Remove old calls outside the window
            while self.calls and \
                  (now - self.calls[0]) > timedelta(seconds=self.period):
                self.calls.popleft()

            # Check if we're at limit
            if len(self.calls) >= self.max_calls:
                # Calculate wait time
                sleep_time = (self.calls[0] +
                            timedelta(seconds=self.period) -
                            now).total_seconds()
                await asyncio.sleep(sleep_time)

            # Record this call
            self.calls.append(now)

# Usage
order_rate_limiter = RateLimiter(max_calls=40, period=1.0)

async def place_order_with_rate_limit(order):
    await order_rate_limiter.acquire()
    return await ibkr_adapter.place_order_async(order)
```

#### Error Handling & Reconnection

**Common Issues:**
1. Connection drops
2. Nightly IB system reset (01:00-02:00 ET Sunday)
3. Order rejection
4. Market data issues

**Reconnection Strategy:**

```python
class ConnectionManager:
    """Manage IBKR connection with auto-reconnect"""

    def __init__(self, adapter: IBKRAsyncAdapter):
        self.adapter = adapter
        self.connected = False
        self.reconnect_task = None

    async def maintain_connection(self):
        """Keep connection alive with auto-reconnect"""
        while True:
            try:
                if not self.connected:
                    await self.connect_with_retry()

                # Check connection health
                await asyncio.sleep(60)

            except Exception as e:
                logger.error(f"Connection error: {e}")
                self.connected = False
                await asyncio.sleep(30)

    async def connect_with_retry(self, max_retries=5):
        """Connect with exponential backoff"""
        for attempt in range(max_retries):
            try:
                self.adapter.connect("127.0.0.1", 4001, 1)
                await asyncio.sleep(2)  # Wait for connection

                if self.adapter.client.isConnected():
                    self.connected = True
                    logger.info("Connected to IBKR")
                    return

            except Exception as e:
                wait_time = min(2 ** attempt, 300)  # Max 5 minutes
                logger.warning(f"Connection attempt {attempt + 1} failed, "
                             f"retrying in {wait_time}s")
                await asyncio.sleep(wait_time)

        raise Exception("Failed to connect after max retries")
```

#### Market Data Integration

**Subscription Management:**

```python
class MarketDataManager:
    """Manage market data subscriptions"""

    def __init__(self, ibkr_adapter):
        self.adapter = ibkr_adapter
        self.subscriptions: Dict[str, int] = {}  # symbol -> req_id
        self.next_req_id = 1000

    async def subscribe(self, symbol: str):
        """Subscribe to real-time data for symbol"""
        if symbol in self.subscriptions:
            return  # Already subscribed

        req_id = self.next_req_id
        self.next_req_id += 1

        # Create contract
        contract = Contract()
        contract.symbol = symbol
        contract.secType = "STK"
        contract.exchange = "SMART"
        contract.currency = "USD"

        # Subscribe
        self.adapter.client.reqMktData(req_id, contract, "", False, False, [])
        self.subscriptions[symbol] = req_id

    async def unsubscribe(self, symbol: str):
        """Unsubscribe from real-time data"""
        if symbol not in self.subscriptions:
            return

        req_id = self.subscriptions[symbol]
        self.adapter.client.cancelMktData(req_id)
        del self.subscriptions[symbol]
```

---

### Market Data API Integration (Financial Modeling Prep)

**Purpose:** Supplement IBKR market data with additional data sources.

**API Details:**
- Provider: Financial Modeling Prep (FMP)
- Cost: $19/month for unlimited access
- Coverage: 70,000+ stocks, 30+ years historical data
- Real-time: Yes (via REST and WebSocket)

**Integration:**

```python
import aiohttp
from typing import List, Dict
from datetime import datetime

class FMPClient:
    """Financial Modeling Prep API client"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://financialmodelingprep.com/api/v3"
        self.session = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, *args):
        await self.session.close()

    async def get_quote(self, symbol: str) -> Dict:
        """Get real-time quote"""
        url = f"{self.base_url}/quote/{symbol}"
        params = {"apikey": self.api_key}

        async with self.session.get(url, params=params) as resp:
            data = await resp.json()
            return data[0] if data else None

    async def get_historical_prices(
        self,
        symbol: str,
        from_date: str,
        to_date: str
    ) -> List[Dict]:
        """Get historical daily prices"""
        url = f"{self.base_url}/historical-price-full/{symbol}"
        params = {
            "apikey": self.api_key,
            "from": from_date,
            "to": to_date
        }

        async with self.session.get(url, params=params) as resp:
            data = await resp.json()
            return data.get("historical", [])

    async def get_real_time_feed(self, symbols: List[str]):
        """WebSocket real-time feed (pseudo-code)"""
        ws_url = f"wss://financialmodelingprep.com/v3/quote"
        async with self.session.ws_connect(ws_url) as ws:
            # Subscribe to symbols
            await ws.send_json({
                "action": "subscribe",
                "symbols": symbols,
                "apikey": self.api_key
            })

            # Process messages
            async for msg in ws:
                yield msg.json()
```

---

## Data Management Architecture

### Database Strategy

**Multi-Database Approach:** Use specialized databases for different data types.

#### 1. PostgreSQL (Relational Data)

**Purpose:** Transactional data, configuration, metadata

**Schema:**

```sql
-- Accounts
CREATE TABLE accounts (
    account_id UUID PRIMARY KEY,
    ibkr_account_id VARCHAR(50) UNIQUE NOT NULL,
    account_type VARCHAR(20),  -- 'CASH', 'MARGIN'
    base_currency VARCHAR(3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Strategies
CREATE TABLE strategies (
    strategy_id UUID PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    enabled BOOLEAN DEFAULT true,
    capital_allocation DECIMAL(5,4),  -- 0.0 to 1.0
    config JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Orders
CREATE TABLE orders (
    order_id UUID PRIMARY KEY,
    ib_order_id INTEGER,
    account_id UUID REFERENCES accounts(account_id),
    strategy_id UUID REFERENCES strategies(strategy_id),
    symbol VARCHAR(20) NOT NULL,
    action VARCHAR(10),  -- 'BUY', 'SELL'
    order_type VARCHAR(20),
    quantity INTEGER NOT NULL,
    limit_price DECIMAL(12,4),
    stop_price DECIMAL(12,4),
    status VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    submitted_at TIMESTAMP,
    filled_at TIMESTAMP,
    filled_quantity INTEGER,
    filled_avg_price DECIMAL(12,4),
    commission DECIMAL(10,4),
    INDEX idx_symbol (symbol),
    INDEX idx_status (status),
    INDEX idx_created_at (created_at)
);

-- Executions
CREATE TABLE executions (
    execution_id UUID PRIMARY KEY,
    order_id UUID REFERENCES orders(order_id),
    ib_exec_id VARCHAR(50),
    symbol VARCHAR(20),
    side VARCHAR(10),
    quantity INTEGER,
    price DECIMAL(12,4),
    commission DECIMAL(10,4),
    executed_at TIMESTAMP,
    INDEX idx_order_id (order_id),
    INDEX idx_executed_at (executed_at)
);

-- Positions
CREATE TABLE positions (
    position_id UUID PRIMARY KEY,
    account_id UUID REFERENCES accounts(account_id),
    symbol VARCHAR(20) NOT NULL,
    quantity INTEGER NOT NULL,
    avg_cost DECIMAL(12,4),
    realized_pnl DECIMAL(12,2) DEFAULT 0,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(account_id, symbol)
);

-- Trading Signals
CREATE TABLE trading_signals (
    signal_id UUID PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    action VARCHAR(10),
    confidence DECIMAL(5,4),
    model_name VARCHAR(100),
    model_version VARCHAR(20),
    features JSONB,
    predicted_return DECIMAL(10,6),
    position_size_pct DECIMAL(5,4),
    stop_loss DECIMAL(12,4),
    take_profit DECIMAL(12,4),
    ttl INTEGER,
    expired BOOLEAN DEFAULT false,
    INDEX idx_symbol_timestamp (symbol, timestamp),
    INDEX idx_timestamp (timestamp)
);

-- Risk Events
CREATE TABLE risk_events (
    event_id UUID PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    severity VARCHAR(20),
    event_type VARCHAR(50),
    message TEXT,
    current_value DECIMAL(15,2),
    limit_value DECIMAL(15,2),
    action_taken VARCHAR(100),
    metadata JSONB
);
```

#### 2. TimescaleDB (Time-Series Data)

**Purpose:** Market data, metrics, performance tracking

**Hypertables:**

```sql
-- Market Data Quotes
CREATE TABLE market_quotes (
    time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    bid DECIMAL(12,4),
    ask DECIMAL(12,4),
    last DECIMAL(12,4),
    volume BIGINT,
    bid_size INTEGER,
    ask_size INTEGER,
    source VARCHAR(20)
);

-- Convert to hypertable
SELECT create_hypertable('market_quotes', 'time');

-- Create indexes
CREATE INDEX idx_market_quotes_symbol_time
    ON market_quotes (symbol, time DESC);

-- OHLCV Bars
CREATE TABLE ohlcv_bars (
    time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    open DECIMAL(12,4),
    high DECIMAL(12,4),
    low DECIMAL(12,4),
    close DECIMAL(12,4),
    volume BIGINT,
    interval VARCHAR(10)  -- '1min', '5min', '1hour', '1day'
);

SELECT create_hypertable('ohlcv_bars', 'time');
CREATE INDEX idx_ohlcv_symbol_time
    ON ohlcv_bars (symbol, time DESC);

-- Performance Metrics
CREATE TABLE performance_metrics (
    time TIMESTAMPTZ NOT NULL,
    strategy_id UUID,
    account_id UUID,
    portfolio_value DECIMAL(15,2),
    cash DECIMAL(15,2),
    positions_value DECIMAL(15,2),
    daily_pnl DECIMAL(15,2),
    cumulative_pnl DECIMAL(15,2),
    num_positions INTEGER,
    num_trades INTEGER
);

SELECT create_hypertable('performance_metrics', 'time');

-- Continuous Aggregates for faster queries
CREATE MATERIALIZED VIEW daily_performance
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS day,
    strategy_id,
    FIRST(portfolio_value, time) AS open_value,
    LAST(portfolio_value, time) AS close_value,
    MAX(portfolio_value) AS high_value,
    MIN(portfolio_value) AS low_value,
    SUM(daily_pnl) AS total_pnl
FROM performance_metrics
GROUP BY day, strategy_id;
```

#### 3. Redis (Caching & Real-time State)

**Purpose:** Hot data, session state, rate limiting

**Key Patterns:**

```python
# Current positions cache
redis_client.hset("positions:current", "AAPL", json.dumps({
    "quantity": 100,
    "avg_cost": 150.50,
    "current_price": 155.20
}))

# Active orders cache
redis_client.setex(
    f"order:{order_id}:status",
    3600,  # 1 hour TTL
    "SUBMITTED"
)

# Market data cache (quotes)
redis_client.setex(
    f"quote:{symbol}",
    60,  # 60 second TTL
    json.dumps(quote_data)
)

# Risk state
redis_client.hset("risk:daily", "pnl", -150.50)
redis_client.hset("risk:daily", "trades_count", 25)

# Rate limiting (using INCR with EXPIRE)
key = f"ratelimit:api:{user_id}:{minute}"
count = redis_client.incr(key)
if count == 1:
    redis_client.expire(key, 60)
if count > 100:
    raise RateLimitExceeded()

# Connection state
redis_client.setex("ibkr:connection:status", 300, "CONNECTED")
```

#### 4. S3/MinIO (Object Storage)

**Purpose:** Model artifacts, backtest results, logs

**Structure:**
```
bucket: trading-system-data
├── models/
│   ├── lstm_momentum/
│   │   ├── v1.2.3/
│   │   │   ├── model.onnx
│   │   │   ├── metadata.json
│   │   │   └── training_log.txt
│   ├── random_forest/
│   └── transformer/
├── backtests/
│   ├── 2025-11-13/
│   │   ├── strategy_001_results.json
│   │   ├── equity_curve.png
│   │   └── trades.csv
├── logs/
│   ├── 2025/11/13/
│   │   ├── trading_engine.log
│   │   ├── market_data.log
│   │   └── risk_manager.log
└── reports/
    └── monthly/
        └── 2025-11/
            └── performance_report.pdf
```

### Data Retention Policy

| Data Type | Retention | Storage | Archival |
|-----------|-----------|---------|----------|
| Market quotes (real-time) | 7 days | TimescaleDB | S3 (compressed) |
| OHLCV bars | 5 years | TimescaleDB | S3 |
| Orders | Forever | PostgreSQL | None |
| Executions | Forever | PostgreSQL | None |
| Positions (history) | Forever | PostgreSQL | S3 (yearly) |
| Trading signals | 90 days | PostgreSQL | S3 |
| Performance metrics | Forever | TimescaleDB | S3 (yearly) |
| Logs | 90 days | File system | S3 |
| Models | Forever | S3 | None |

---

## AI/ML Integration

### Model Development Pipeline

```
┌────────────────────────────────────────────────────────────┐
│              Model Development Pipeline                     │
├────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌──────────────┐       ┌──────────────┐                  │
│  │ Data         │  ───► │ Feature      │                  │
│  │ Collection   │       │ Engineering  │                  │
│  └──────────────┘       └──────────────┘                  │
│                               │                             │
│                               ▼                             │
│                      ┌──────────────┐                      │
│                      │ Model        │                      │
│                      │ Training     │                      │
│                      └──────────────┘                      │
│                               │                             │
│                               ▼                             │
│                      ┌──────────────┐                      │
│                      │ Backtesting  │                      │
│                      │ & Validation │                      │
│                      └──────────────┘                      │
│                               │                             │
│                               ▼                             │
│                      ┌──────────────┐                      │
│                      │ Model        │                      │
│                      │ Evaluation   │                      │
│                      └──────────────┘                      │
│                               │                             │
│                    ┌──────────┴──────────┐                 │
│                    │                     │                 │
│                    ▼                     ▼                 │
│            ┌──────────────┐      ┌──────────────┐         │
│            │ APPROVE      │      │ REJECT       │         │
│            └──────────────┘      └──────────────┘         │
│                    │                                       │
│                    ▼                                       │
│            ┌──────────────┐                                │
│            │ ONNX Export  │                                │
│            └──────────────┘                                │
│                    │                                       │
│                    ▼                                       │
│            ┌──────────────┐                                │
│            │ Model        │                                │
│            │ Registry     │                                │
│            │ (MLflow)     │                                │
│            └──────────────┘                                │
│                    │                                       │
│                    ▼                                       │
│            ┌──────────────┐                                │
│            │ Production   │                                │
│            │ Deployment   │                                │
│            └──────────────┘                                │
│                                                             │
└────────────────────────────────────────────────────────────┘
```

### Feature Engineering

**Technical Indicators:**
- Simple Moving Average (SMA)
- Exponential Moving Average (EMA)
- Relative Strength Index (RSI)
- MACD (Moving Average Convergence Divergence)
- Bollinger Bands
- Average True Range (ATR)
- Stochastic Oscillator
- On-Balance Volume (OBV)

**Price Features:**
- Returns (1-day, 5-day, 20-day)
- Log returns
- Volatility (rolling std)
- Price momentum
- Price relative to moving averages

**Volume Features:**
- Volume change
- Volume relative to average
- Volume price trend

**Market Microstructure:**
- Bid-ask spread
- Order book imbalance (if available)
- Trade intensity

**Cross-Asset Features:**
- Correlation with market index
- Sector relative strength
- Cross-asset momentum

**Alternative Data:**
- News sentiment score
- Social media sentiment
- Analyst ratings changes

### Model Types & Use Cases

#### 1. Classification Models

**Purpose:** Predict direction (UP/DOWN/NEUTRAL)

**Algorithms:**
- Random Forest Classifier
- Gradient Boosting (XGBoost, LightGBM)
- Neural Networks

**Output:**
```python
{
    "prediction": "BUY",  # UP/DOWN/NEUTRAL -> BUY/SELL/HOLD
    "confidence": 0.78,
    "probabilities": {
        "UP": 0.78,
        "DOWN": 0.15,
        "NEUTRAL": 0.07
    }
}
```

#### 2. Regression Models

**Purpose:** Predict returns magnitude

**Algorithms:**
- Linear Regression (baseline)
- Ridge/Lasso Regression
- Random Forest Regressor
- Neural Networks

**Output:**
```python
{
    "predicted_return_1d": 0.023,  # 2.3% expected return
    "predicted_return_5d": 0.056,
    "confidence_interval": [-0.01, 0.056]
}
```

#### 3. Time Series Models

**Purpose:** Capture temporal dependencies

**Algorithms:**
- LSTM (Long Short-Term Memory)
- GRU (Gated Recurrent Unit)
- Transformer models
- Temporal Convolutional Networks

**Architecture Example (LSTM):**
```python
import torch
import torch.nn as nn

class LSTMPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMPredictor, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.lstm = nn.LSTM(
            input_size,
            hidden_size,
            num_layers,
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # x shape: (batch, seq_len, input_size)
        h0 = torch.zeros(self.num_layers, x.size(0),
                        self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0),
                        self.hidden_size).to(x.device)

        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])  # Last time step
        return out
```

#### 4. Ensemble Models

**Purpose:** Combine multiple models for better accuracy

**Strategy:**
- Weighted average of predictions
- Stacking (meta-model on top)
- Voting (majority vote)

**Implementation:**
```python
class EnsemblePredictor:
    def __init__(self, models, weights):
        self.models = models
        self.weights = weights

    def predict(self, features):
        predictions = []
        for model in self.models:
            pred = model.predict(features)
            predictions.append(pred)

        # Weighted average
        ensemble_pred = sum(w * p for w, p in
                          zip(self.weights, predictions))
        return ensemble_pred
```

### Model Evaluation Metrics

**Trading-Specific Metrics:**

1. **Sharpe Ratio:**
   ```python
   sharpe_ratio = (mean_return - risk_free_rate) / std_return
   ```

2. **Sortino Ratio:**
   ```python
   sortino_ratio = (mean_return - risk_free_rate) / downside_deviation
   ```

3. **Maximum Drawdown:**
   ```python
   cumulative_returns = (1 + returns).cumprod()
   running_max = cumulative_returns.cummax()
   drawdown = (cumulative_returns - running_max) / running_max
   max_drawdown = drawdown.min()
   ```

4. **Win Rate:**
   ```python
   win_rate = (winning_trades / total_trades) * 100
   ```

5. **Profit Factor:**
   ```python
   profit_factor = gross_profit / gross_loss
   ```

6. **Calmar Ratio:**
   ```python
   calmar_ratio = annual_return / abs(max_drawdown)
   ```

### Model Deployment

**Format:** ONNX (Open Neural Network Exchange)

**Benefits:**
- Cross-platform compatibility
- Optimized for inference
- Smaller model size
- Framework agnostic

**Export Example:**
```python
import torch
import torch.onnx

# Export PyTorch model to ONNX
model = LSTMPredictor(...)
model.eval()

dummy_input = torch.randn(1, 30, 50)  # (batch, seq_len, features)
torch.onnx.export(
    model,
    dummy_input,
    "lstm_momentum_v1.2.3.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)
```

**Inference with ONNX Runtime:**
```python
import onnxruntime as ort
import numpy as np

class ONNXModel:
    def __init__(self, model_path):
        self.session = ort.InferenceSession(model_path)

    def predict(self, features: np.ndarray):
        input_name = self.session.get_inputs()[0].name
        output_name = self.session.get_outputs()[0].name

        result = self.session.run(
            [output_name],
            {input_name: features.astype(np.float32)}
        )
        return result[0]
```

---

## Security Design

### Security Principles

1. **Defense in Depth:** Multiple layers of security
2. **Least Privilege:** Minimum necessary permissions
3. **Encryption:** Data encrypted at rest and in transit
4. **Audit Logging:** Comprehensive audit trail
5. **Secrets Management:** Secure credential storage

### Authentication & Authorization

#### Service-to-Service Authentication

**Method:** mTLS (Mutual TLS) + JWT

**Implementation:**
```python
from fastapi import Security, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(
    credentials: HTTPAuthorizationCredentials = Security(security)
):
    token = credentials.credentials
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")

@app.post("/api/v1/orders")
async def create_order(
    order: Order,
    token_payload = Depends(verify_token)
):
    # Only trading service can create orders
    if token_payload["service"] != "trading_service":
        raise HTTPException(status_code=403)
    # ... create order
```

#### User Authentication (Dashboard)

**Method:** OAuth 2.0 + OIDC

**Providers:**
- Auth0
- AWS Cognito
- Keycloak (self-hosted)

### Secrets Management

**Technology:** HashiCorp Vault or AWS Secrets Manager

**Secrets Stored:**
- IBKR credentials
- API keys (FMP, etc.)
- Database passwords
- Encryption keys
- Service tokens

**Access Pattern:**
```python
import hvac

# Initialize Vault client
vault_client = hvac.Client(url='https://vault.example.com')
vault_client.token = os.environ['VAULT_TOKEN']

# Read secret
secret = vault_client.secrets.kv.v2.read_secret_version(
    path='trading-system/ibkr'
)
ibkr_username = secret['data']['data']['username']
ibkr_password = secret['data']['data']['password']
```

### Network Security

**Architecture:**

```
┌─────────────────────────────────────────────────────┐
│                    Internet                          │
└─────────────────────────────────────────────────────┘
                         │
                         ▼
              ┌──────────────────┐
              │  WAF / CDN       │
              │  (Cloudflare)    │
              └──────────────────┘
                         │
                         ▼
              ┌──────────────────┐
              │  Load Balancer   │
              │  (TLS Termination│
              └──────────────────┘
                         │
        ┌────────────────┴────────────────┐
        │                                  │
        ▼                                  ▼
┌──────────────┐                  ┌──────────────┐
│ DMZ Zone     │                  │ Private Zone │
│              │                  │              │
│ - Dashboard  │◄────────────────►│ - Services   │
│ - API Gateway│  VPC Peering     │ - Databases  │
│              │                  │ - IB Gateway │
└──────────────┘                  └──────────────┘
```

**Firewall Rules:**
- Dashboard: Allow HTTPS (443) from anywhere
- API Gateway: Allow HTTPS (443) from dashboard subnet
- Services: No direct internet access
- IB Gateway: Allow outbound to IBKR IPs only
- Databases: Allow from services subnet only

### Data Encryption

#### At Rest

**Database:** PostgreSQL with encryption enabled
```sql
-- Enable encryption
CREATE EXTENSION pgcrypto;

-- Encrypt sensitive columns
CREATE TABLE api_keys (
    id UUID PRIMARY KEY,
    service VARCHAR(50),
    encrypted_key BYTEA,  -- Encrypted using pgcrypto
    created_at TIMESTAMP
);

-- Insert encrypted data
INSERT INTO api_keys (id, service, encrypted_key)
VALUES (
    gen_random_uuid(),
    'fmp',
    pgp_sym_encrypt('api_key_value', 'encryption_password')
);

-- Query encrypted data
SELECT pgp_sym_decrypt(encrypted_key, 'encryption_password')
FROM api_keys WHERE service = 'fmp';
```

**S3/MinIO:** Server-side encryption (SSE-S3 or SSE-KMS)

#### In Transit

**All Communications:** TLS 1.3

**Certificate Management:**
- Let's Encrypt for public endpoints
- Internal CA for service-to-service
- Automatic rotation

### Audit Logging

**What to Log:**
- All order placements, modifications, cancellations
- All authentication attempts
- All API calls
- Configuration changes
- Risk limit breaches
- System errors

**Log Format (Structured JSON):**
```json
{
  "timestamp": "2025-11-13T10:30:45.123Z",
  "level": "INFO",
  "service": "order_service",
  "event_type": "ORDER_PLACED",
  "user_id": "system",
  "ip_address": "10.0.1.50",
  "order_id": "a1b2c3d4-...",
  "symbol": "AAPL",
  "action": "BUY",
  "quantity": 100,
  "status": "SUBMITTED"
}
```

**Storage:**
- Local: File system (rotate daily)
- Centralized: ELK stack (Elasticsearch, Logstash, Kibana)
- Long-term: S3 (compressed, 90-day retention)

### API Security

**Rate Limiting:**
```python
from fastapi import Request
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

@app.get("/api/v1/market-data/quote/{symbol}")
@limiter.limit("100/minute")
async def get_quote(request: Request, symbol: str):
    # ... implementation
```

**Input Validation:**
```python
from pydantic import BaseModel, validator, Field
from decimal import Decimal

class OrderRequest(BaseModel):
    symbol: str = Field(..., regex="^[A-Z]{1,5}$")
    action: str = Field(..., regex="^(BUY|SELL)$")
    quantity: int = Field(..., gt=0, le=10000)
    order_type: str = Field(..., regex="^(MARKET|LIMIT)$")
    limit_price: Optional[Decimal] = None

    @validator('limit_price')
    def validate_limit_price(cls, v, values):
        if values.get('order_type') == 'LIMIT' and v is None:
            raise ValueError('limit_price required for LIMIT orders')
        if v is not None and v <= 0:
            raise ValueError('limit_price must be positive')
        return v
```

**CORS Configuration:**
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://dashboard.trading-system.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)
```

---

## Risk Management Framework

### Risk Hierarchy

```
Portfolio Level Risk
├── Maximum Daily Loss
├── Maximum Drawdown
├── Maximum Leverage
└── Cash Reserve Requirements

Strategy Level Risk
├── Capital Allocation Limits
├── Strategy Correlation Limits
└── Strategy Drawdown Limits

Position Level Risk
├── Maximum Position Size
├── Sector Concentration Limits
├── Correlation Limits
└── Stop-Loss Requirements

Order Level Risk
├── Maximum Order Size
├── Order Rate Limits
└── Pre-Trade Validation
```

### Risk Checks Implementation

```python
from dataclasses import dataclass
from decimal import Decimal
from typing import Optional

@dataclass
class RiskCheckResult:
    passed: bool
    reason: Optional[str] = None
    limit_name: str = ""
    current_value: Decimal = Decimal('0')
    limit_value: Decimal = Decimal('0')

class RiskManager:
    """Comprehensive risk management"""

    def __init__(self, config: RiskConfig):
        self.config = config
        self.redis = redis.Redis()

    async def pre_trade_check(self, order: Order) -> RiskCheckResult:
        """Perform all pre-trade risk checks"""

        # Get current portfolio state
        portfolio = await self.get_portfolio_state()

        # Check 1: Daily loss limit
        result = await self.check_daily_loss(portfolio)
        if not result.passed:
            return result

        # Check 2: Position size limit
        result = await self.check_position_size(order, portfolio)
        if not result.passed:
            return result

        # Check 3: Order size limit
        result = await self.check_order_size(order)
        if not result.passed:
            return result

        # Check 4: Concentration limit
        result = await self.check_concentration(order, portfolio)
        if not result.passed:
            return result

        # Check 5: Order rate limit
        result = await self.check_order_rate()
        if not result.passed:
            return result

        return RiskCheckResult(passed=True)

    async def check_daily_loss(self, portfolio) -> RiskCheckResult:
        """Check if daily loss exceeds limit"""
        daily_pnl = portfolio.daily_pnl
        portfolio_value = portfolio.total_value

        # Check percentage limit
        daily_pnl_pct = (daily_pnl / portfolio_value) * 100
        max_loss_pct = self.config.max_daily_loss_pct

        if daily_pnl_pct < -max_loss_pct:
            return RiskCheckResult(
                passed=False,
                reason=f"Daily loss {daily_pnl_pct:.2f}% exceeds limit",
                limit_name="max_daily_loss_pct",
                current_value=abs(daily_pnl_pct),
                limit_value=max_loss_pct
            )

        # Check absolute dollar limit
        max_loss_usd = self.config.max_daily_loss_usd
        if daily_pnl < -max_loss_usd:
            return RiskCheckResult(
                passed=False,
                reason=f"Daily loss ${abs(daily_pnl):.2f} exceeds limit",
                limit_name="max_daily_loss_usd",
                current_value=abs(daily_pnl),
                limit_value=max_loss_usd
            )

        return RiskCheckResult(passed=True)

    async def check_position_size(
        self,
        order: Order,
        portfolio
    ) -> RiskCheckResult:
        """Check if position size will exceed limit"""

        # Calculate new position size after order
        current_position = portfolio.get_position(order.symbol)
        new_quantity = current_position.quantity

        if order.action == 'BUY':
            new_quantity += order.quantity
        else:
            new_quantity -= order.quantity

        # Calculate position value
        current_price = await self.get_current_price(order.symbol)
        position_value = abs(new_quantity) * current_price

        # Check percentage limit
        position_pct = (position_value / portfolio.total_value) * 100
        max_position_pct = self.config.max_position_size_pct

        if position_pct > max_position_pct:
            return RiskCheckResult(
                passed=False,
                reason=f"Position size {position_pct:.2f}% exceeds limit",
                limit_name="max_position_size_pct",
                current_value=position_pct,
                limit_value=max_position_pct
            )

        return RiskCheckResult(passed=True)

    async def check_order_rate(self) -> RiskCheckResult:
        """Check order rate limiting"""

        # Get order count from Redis
        minute_key = f"orders:count:{datetime.now().strftime('%Y%m%d%H%M')}"
        order_count = int(self.redis.get(minute_key) or 0)

        max_orders_per_minute = self.config.max_orders_per_minute

        if order_count >= max_orders_per_minute:
            return RiskCheckResult(
                passed=False,
                reason=f"Order rate limit exceeded",
                limit_name="max_orders_per_minute",
                current_value=order_count,
                limit_value=max_orders_per_minute
            )

        return RiskCheckResult(passed=True)
```

### Stop-Loss Management

**Automatic Stop-Loss Placement:**

```python
class StopLossManager:
    """Manage stop-loss orders"""

    async def create_stop_loss(
        self,
        position: Position,
        stop_loss_pct: float
    ):
        """Create stop-loss order for position"""

        # Calculate stop price
        if position.quantity > 0:  # Long position
            stop_price = position.avg_cost * (1 - stop_loss_pct / 100)
            action = 'SELL'
        else:  # Short position
            stop_price = position.avg_cost * (1 + stop_loss_pct / 100)
            action = 'BUY'

        # Create stop order
        order = Order(
            order_id=str(uuid.uuid4()),
            symbol=position.symbol,
            action=action,
            order_type='STOP',
            quantity=abs(position.quantity),
            stop_price=Decimal(str(stop_price)),
            time_in_force='GTC',
            status='NEW'
        )

        await self.order_service.place_order(order)

    async def update_trailing_stop(
        self,
        position: Position,
        trailing_pct: float
    ):
        """Update trailing stop-loss"""

        current_price = await self.market_data.get_quote(position.symbol)

        if position.quantity > 0:  # Long position
            # Trail stop up as price increases
            new_stop = current_price.last * (1 - trailing_pct / 100)

            # Only update if new stop is higher
            if new_stop > position.stop_price:
                await self.update_stop_price(position, new_stop)
```

### Circuit Breakers

**System-Wide Trading Halt:**

```python
class CircuitBreaker:
    """Emergency trading halt mechanism"""

    def __init__(self):
        self.redis = redis.Redis()
        self.enabled = True

    async def check_conditions(self, portfolio):
        """Check if circuit breaker should trip"""

        # Condition 1: Large drawdown
        if portfolio.current_drawdown > 0.15:  # 15%
            await self.trip("Large drawdown detected")
            return

        # Condition 2: Rapid loss
        if portfolio.hourly_loss < -0.05:  # 5% in 1 hour
            await self.trip("Rapid loss detected")
            return

        # Condition 3: High error rate
        error_rate = await self.get_error_rate()
        if error_rate > 0.10:  # 10% error rate
            await self.trip("High error rate")
            return

    async def trip(self, reason: str):
        """Trip circuit breaker - halt all trading"""

        logger.critical(f"CIRCUIT BREAKER TRIPPED: {reason}")

        # Set flag in Redis
        self.redis.set("circuit_breaker:tripped", "true")
        self.enabled = False

        # Cancel all open orders
        await self.cancel_all_orders()

        # Send critical alerts
        await self.send_critical_alert(
            f"Trading halted: {reason}"
        )

        # Optionally close all positions
        if self.config.auto_close_on_circuit_breaker:
            await self.close_all_positions()

    async def reset(self):
        """Reset circuit breaker (manual intervention required)"""
        self.redis.delete("circuit_breaker:tripped")
        self.enabled = True
        logger.info("Circuit breaker reset")
```

---

## Deployment Strategy

### Deployment Environment

**Target:** Cloud Infrastructure (AWS/Azure/GCP) or Self-Hosted

**Recommended:** AWS for this design

### Infrastructure as Code

**Technology:** Terraform

**Structure:**
```
infrastructure/
├── terraform/
│   ├── modules/
│   │   ├── vpc/
│   │   ├── ecs/
│   │   ├── rds/
│   │   ├── redis/
│   │   └── monitoring/
│   ├── environments/
│   │   ├── dev/
│   │   ├── staging/
│   │   └── production/
│   └── main.tf
```

### Containerization

**Technology:** Docker + Docker Compose (local) / ECS (production)

**Dockerfile Example:**
```dockerfile
# Market Data Service
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY src/ ./src/
COPY config/ ./config/

# Non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health')"

CMD ["python", "-m", "uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Docker Compose (Development):**
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: trading_system
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  timescaledb:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_DB: market_data
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - timescale_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

  nats:
    image: nats:latest
    command: "--jetstream --store_dir /data"
    volumes:
      - nats_data:/data
    ports:
      - "4222:4222"
      - "8222:8222"

  market_data_service:
    build:
      context: .
      dockerfile: services/market_data/Dockerfile
    environment:
      - FMP_API_KEY=${FMP_API_KEY}
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
    depends_on:
      - redis
      - nats
      - timescaledb

  ai_ml_service:
    build:
      context: .
      dockerfile: services/ai_ml/Dockerfile
    volumes:
      - ./models:/app/models
    environment:
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
    depends_on:
      - redis
      - nats

  order_service:
    build:
      context: .
      dockerfile: services/order/Dockerfile
    environment:
      - DB_URL=postgresql://admin:${DB_PASSWORD}@postgres:5432/trading_system
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
      - IBKR_HOST=host.docker.internal
      - IBKR_PORT=4001
    depends_on:
      - postgres
      - redis
      - nats
    network_mode: "host"  # To access IB Gateway on localhost

  dashboard:
    build:
      context: .
      dockerfile: services/dashboard/Dockerfile
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://api_gateway:8080

volumes:
  postgres_data:
  timescale_data:
  redis_data:
  nats_data:
```

### Production Deployment (AWS ECS)

**Architecture:**

```
┌─────────────────────────────────────────────────────┐
│                     AWS Cloud                        │
├─────────────────────────────────────────────────────┤
│                                                      │
│  ┌─────────────────────────────────────────────┐   │
│  │  VPC (10.0.0.0/16)                          │   │
│  │                                              │   │
│  │  ┌──────────────────────────────────────┐  │   │
│  │  │ Public Subnet (10.0.1.0/24)          │  │   │
│  │  │  - ALB (Application Load Balancer)   │  │   │
│  │  │  - NAT Gateway                        │  │   │
│  │  └──────────────────────────────────────┘  │   │
│  │                                              │   │
│  │  ┌──────────────────────────────────────┐  │   │
│  │  │ Private Subnet (10.0.2.0/24)         │  │   │
│  │  │  - ECS Fargate Tasks                 │  │   │
│  │  │    * Market Data Service             │  │   │
│  │  │    * AI/ML Service                   │  │   │
│  │  │    * Order Service                   │  │   │
│  │  │    * Position Service                │  │   │
│  │  │    * Risk Manager                    │  │   │
│  │  │  - EC2 (IB Gateway)                  │  │   │
│  │  └──────────────────────────────────────┘  │   │
│  │                                              │   │
│  │  ┌──────────────────────────────────────┐  │   │
│  │  │ Data Subnet (10.0.3.0/24)            │  │   │
│  │  │  - RDS PostgreSQL                    │  │   │
│  │  │  - RDS TimescaleDB                   │  │   │
│  │  │  - ElastiCache Redis Cluster         │  │   │
│  │  └──────────────────────────────────────┘  │   │
│  │                                              │   │
│  └─────────────────────────────────────────────┘   │
│                                                      │
│  External Services:                                 │
│  - S3 (Models, Logs, Backups)                      │
│  - CloudWatch (Monitoring, Logs)                   │
│  - Secrets Manager (Credentials)                   │
│  - ECR (Container Registry)                        │
│                                                      │
└─────────────────────────────────────────────────────┘
```

### CI/CD Pipeline

**Technology:** GitHub Actions

**Pipeline Stages:**

```yaml
# .github/workflows/deploy.yml
name: Deploy Trading System

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run tests
        run: pytest tests/ --cov=src/

      - name: Run linter
        run: flake8 src/

      - name: Type checking
        run: mypy src/

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push Docker images
        run: |
          docker build -t trading-system/market-data:${{ github.sha }} services/market_data/
          docker push trading-system/market-data:${{ github.sha }}
          # ... repeat for other services

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster trading-system \
            --service market-data-service \
            --force-new-deployment
```

### Blue-Green Deployment

**Strategy:**
1. Deploy new version (green) alongside current version (blue)
2. Run smoke tests on green environment
3. Gradually shift traffic from blue to green
4. Monitor metrics
5. Rollback if issues detected
6. Decommission blue environment

### Scaling Strategy

**Horizontal Scaling:**

| Service | Min Instances | Max Instances | Scale Metric |
|---------|---------------|---------------|--------------|
| Market Data | 2 | 5 | CPU > 70% |
| AI/ML | 1 | 3 | Queue depth > 100 |
| Order | 2 | 4 | CPU > 60% |
| Position | 1 | 2 | CPU > 70% |
| Risk Manager | 2 | 2 | Always 2 (HA) |
| Dashboard | 1 | 3 | HTTP requests |

**IB Gateway:**
- Single EC2 instance (m5.large)
- Reserved instance for cost savings
- Auto-recovery enabled
- EBS snapshots every 6 hours

---

## Monitoring & Observability

### Metrics Collection

**Technology:** Prometheus + Grafana

**Key Metrics:**

**System Metrics:**
- CPU usage per service
- Memory usage per service
- Network I/O
- Disk I/O
- Container restart count

**Application Metrics:**
- Request rate (requests/second)
- Request latency (p50, p95, p99)
- Error rate (errors/second)
- Queue depth (NATS)
- Cache hit rate (Redis)

**Trading Metrics:**
- Orders placed per minute
- Order execution latency
- Order rejection rate
- Fill rate
- Slippage (actual vs expected price)

**Performance Metrics:**
- Real-time P&L
- Daily P&L
- Sharpe ratio (rolling)
- Win rate
- Maximum drawdown

**Risk Metrics:**
- Current portfolio exposure
- Daily loss
- Position sizes
- Sector concentration
- Correlation exposure

### Logging

**Centralized Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)

**Log Levels:**
- DEBUG: Detailed diagnostic information
- INFO: General informational messages
- WARNING: Warning messages (degraded performance)
- ERROR: Error messages (recoverable errors)
- CRITICAL: Critical errors (system halt)

**Structured Logging:**
```python
import structlog

logger = structlog.get_logger()

logger.info(
    "order_placed",
    order_id=order_id,
    symbol=symbol,
    action=action,
    quantity=quantity,
    order_type=order_type,
    strategy_id=strategy_id
)
```

### Alerting

**Technology:** Prometheus Alertmanager

**Alert Categories:**

**Critical Alerts (PagerDuty + SMS):**
- IBKR connection lost
- Circuit breaker tripped
- Daily loss limit exceeded
- Service crashed
- Database connection lost

**Warning Alerts (Email + Slack):**
- High error rate (> 5%)
- High latency (> 1s p95)
- Low cache hit rate (< 80%)
- Disk usage > 80%
- Position size near limit

**Info Alerts (Slack):**
- Daily P&L summary
- Strategy performance update
- Model deployment successful

**Alert Configuration:**
```yaml
groups:
  - name: trading_system
    rules:
      - alert: IBKRConnectionDown
        expr: ibkr_connection_status == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "IBKR connection is down"
          description: "Trading system cannot connect to Interactive Brokers"

      - alert: DailyLossLimitExceeded
        expr: abs(daily_pnl_pct) > 2.0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Daily loss limit exceeded"
          description: "Daily loss is {{ $value }}%, limit is 2%"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"
```

### Dashboards

**Grafana Dashboards:**

**1. System Overview:**
- Service health status
- CPU/Memory usage
- Request rates
- Error rates
- Latency histograms

**2. Trading Dashboard:**
- Current positions
- Open orders
- Today's P&L
- Recent trades
- Order execution timeline

**3. Performance Dashboard:**
- Cumulative P&L chart
- Daily returns
- Sharpe ratio trend
- Win rate trend
- Maximum drawdown

**4. Risk Dashboard:**
- Portfolio exposure
- Position sizes
- Sector concentration
- Daily loss tracking
- Risk limit utilization

**5. Strategy Dashboard:**
- Per-strategy P&L
- Signal accuracy
- Strategy allocation
- Model performance metrics

### Distributed Tracing

**Technology:** OpenTelemetry + Jaeger

**Use Case:** Trace request flow across services

**Example Trace:**
```
Market Data Received
  └─> Feature Engineering (AI/ML Service) [50ms]
      └─> Model Inference [120ms]
          └─> Signal Generated [5ms]
              └─> Strategy Executor [10ms]
                  └─> Risk Check (Risk Manager) [30ms]
                      └─> Order Placed (Order Service) [40ms]
                          └─> IBKR API Call [200ms]

Total Latency: 455ms
```

---

## Compliance & Regulatory

### FCA Compliance (UK)

**Regulatory Requirements:**
1. **Authorized Broker:** Using FCA-authorized Interactive Brokers (U.K.) Limited
2. **Investor Protection:** FSCS protection up to £85,000
3. **Best Execution:** Demonstrate best execution practices
4. **Record Keeping:** Maintain comprehensive audit trails
5. **Risk Disclosure:** Clear risk warnings for automated trading

### MiFID II Compliance

**Requirements:**
- **Transaction Reporting:** Report all transactions to FCA
- **Best Execution Reports:** Annual best execution reports
- **Client Asset Protection:** Segregate client assets
- **Record Retention:** Keep records for 5 years minimum

### Audit Trail Requirements

**Must Record:**
- All orders (placed, modified, cancelled)
- All executions
- All risk limit breaches
- All system configuration changes
- All user actions
- All API calls

**Data Retention:** 5 years minimum

**Implementation:**
```python
class AuditLogger:
    """Immutable audit log"""

    async def log_order(self, order: Order, user: str):
        """Log order placement"""
        await self.db.execute("""
            INSERT INTO audit_log (
                timestamp, event_type, user_id,
                order_id, symbol, action, quantity, details
            ) VALUES (
                NOW(), 'ORDER_PLACED', $1,
                $2, $3, $4, $5, $6
            )
        """, user, order.order_id, order.symbol,
            order.action, order.quantity, order.to_json())
```

### Tax Considerations (UK)

**Capital Gains Tax:**
- Trading profits subject to CGT
- Annual CGT allowance (£6,000 for 2025/26)
- 10% basic rate, 20% higher rate

**Record Keeping for Tax:**
- All buy transactions (date, quantity, price, costs)
- All sell transactions (date, quantity, price, proceeds)
- Calculate gains/losses per transaction
- Annual tax return filing

**Implementation:**
```python
class TaxCalculator:
    """Calculate capital gains for UK tax"""

    def calculate_cgt_liability(
        self,
        trades: List[Trade],
        tax_year: str
    ) -> Decimal:
        """Calculate CGT for tax year"""

        gains = []
        for trade in trades:
            if trade.side == 'SELL':
                # Match with corresponding buy (FIFO)
                cost_basis = self.get_cost_basis(trade)
                proceeds = trade.quantity * trade.price
                gain = proceeds - cost_basis - trade.costs
                gains.append(gain)

        total_gains = sum(gains)
        annual_allowance = Decimal('6000')

        if total_gains <= annual_allowance:
            return Decimal('0')

        taxable_gains = total_gains - annual_allowance
        # Simplified: assume higher rate
        tax_liability = taxable_gains * Decimal('0.20')

        return tax_liability
```

---

## Disaster Recovery & Business Continuity

### Backup Strategy

**Database Backups:**
- **PostgreSQL:** Daily full backups, continuous WAL archiving
- **TimescaleDB:** Daily snapshots, 30-day retention
- **Redis:** Daily RDB snapshots, AOF persistence

**Backup Schedule:**
```
Daily:  02:00 UTC - Full database backup to S3
Hourly: XX:05 UTC - Incremental backup (WAL/AOF)
Weekly: Sunday 03:00 UTC - Full system snapshot
```

**Retention Policy:**
- Daily backups: 30 days
- Weekly backups: 1 year
- Monthly backups: 5 years (compliance)

### Recovery Procedures

**RTO (Recovery Time Objective):** 1 hour
**RPO (Recovery Point Objective):** 5 minutes

**Disaster Scenarios:**

**1. Database Failure:**
```
1. Promote read replica to primary (5 minutes)
2. Update application connection strings
3. Verify data integrity
4. Resume trading operations
```

**2. Service Failure:**
```
1. ECS auto-recovery kicks in (2 minutes)
2. Health checks validate new instance
3. Load balancer routes traffic
4. No manual intervention needed
```

**3. Complete Region Failure:**
```
1. Activate DR region (15 minutes)
2. Restore database from S3 backup
3. Deploy services from container registry
4. Update DNS to point to DR region
5. Resume operations
```

**4. IB Gateway Failure:**
```
1. Auto-restart IB Gateway (2 minutes)
2. Trading system reconnects automatically
3. Reconcile positions with IBKR
4. Resume trading
```

### High Availability

**Service Level:**
- All critical services run with minimum 2 instances
- Cross-AZ deployment for AWS
- Health checks with automatic replacement

**Database Level:**
- PostgreSQL Multi-AZ with automatic failover
- Redis Cluster with replication

**Network Level:**
- Multiple availability zones
- Auto-scaling groups
- Load balancing

---

## Scalability & Performance

### Performance Targets

| Operation | Target Latency | Measurement |
|-----------|----------------|-------------|
| Market data ingestion | < 50ms | Time from FMP to internal queue |
| Signal generation | < 500ms | Time from data to signal |
| Order placement | < 200ms | Time from signal to IBKR |
| Order execution | < 1s | Time from placement to fill |
| Risk check | < 50ms | Pre-trade validation |
| Dashboard update | < 100ms | UI responsiveness |

### Optimization Strategies

**1. Caching:**
- Redis for market data (60s TTL)
- Redis for reference data (24h TTL)
- Redis for position data (real-time updates)

**2. Database Optimization:**
- Indexed queries on hot paths
- Connection pooling (max 50 connections)
- Read replicas for analytics
- Partitioning for time-series data

**3. Async Processing:**
- Non-blocking I/O (asyncio)
- Message queue for decoupling
- Parallel model inference

**4. Model Optimization:**
- ONNX Runtime for 2-10x speedup
- Batch inference where possible
- Model quantization for smaller models

### Load Testing

**Tool:** Locust

**Test Scenarios:**
1. **Normal Load:** 10 orders/minute, 100 symbols
2. **Peak Load:** 50 orders/minute, 500 symbols
3. **Stress Test:** 100 orders/minute, 1000 symbols

**Expected Results:**
- System handles peak load without degradation
- Latency stays below targets at normal load
- Graceful degradation under stress

---

## Technology Stack

### Programming Languages
- **Primary:** Python 3.11+
- **Frontend:** TypeScript/React
- **Scripting:** Bash

### Frameworks & Libraries

**Backend:**
- FastAPI (REST APIs)
- asyncio (Async I/O)
- SQLAlchemy (ORM)
- Pydantic (Data validation)
- ibapi (Interactive Brokers API)
- aiohttp (HTTP client)

**AI/ML:**
- PyTorch (Deep learning)
- scikit-learn (Classical ML)
- pandas (Data manipulation)
- numpy (Numerical computing)
- TA-Lib (Technical analysis)
- ONNX Runtime (Inference)
- MLflow (Model registry)

**Frontend:**
- React 18
- TypeScript
- Material-UI
- Recharts (Charts)
- WebSocket (Real-time updates)

### Infrastructure

**Databases:**
- PostgreSQL 15 (Relational data)
- TimescaleDB (Time-series data)
- Redis 7 (Cache & state)
- ClickHouse (Analytics, optional)

**Message Queue:**
- NATS with JetStream (Pub/sub, persistent)

**Storage:**
- S3/MinIO (Object storage)

**Monitoring:**
- Prometheus (Metrics)
- Grafana (Visualization)
- Jaeger (Tracing)
- ELK Stack (Logging)

**Deployment:**
- Docker (Containerization)
- Terraform (IaC)
- AWS ECS (Container orchestration)
- GitHub Actions (CI/CD)

### Development Tools
- Git (Version control)
- pytest (Testing)
- Black (Code formatting)
- mypy (Type checking)
- flake8 (Linting)
- pre-commit (Git hooks)

---

## Development Roadmap

### Phase 1: Foundation (Weeks 1-4)

**Week 1: Project Setup**
- [ ] Initialize Git repository
- [ ] Set up development environment
- [ ] Configure Docker Compose for local development
- [ ] Set up databases (PostgreSQL, TimescaleDB, Redis)
- [ ] Implement basic project structure

**Week 2: IBKR Integration**
- [ ] Set up IB Gateway (paper trading)
- [ ] Implement IBKR API adapter
- [ ] Test connection and authentication
- [ ] Implement order placement
- [ ] Implement position retrieval
- [ ] Test with paper trading account

**Week 3: Market Data Service**
- [ ] Implement FMP API client
- [ ] Set up market data streaming
- [ ] Implement data normalization
- [ ] Set up NATS message queue
- [ ] Implement data storage (TimescaleDB)
- [ ] Implement caching (Redis)

**Week 4: Order & Position Services**
- [ ] Implement order service
- [ ] Implement order state machine
- [ ] Implement position service
- [ ] Implement position reconciliation
- [ ] Write unit tests
- [ ] Integration testing

### Phase 2: AI/ML Integration (Weeks 5-8)

**Week 5: Feature Engineering**
- [ ] Implement technical indicators
- [ ] Implement feature calculation pipeline
- [ ] Set up feature store
- [ ] Historical data pipeline
- [ ] Feature validation

**Week 6: Model Development**
- [ ] Develop baseline models (simple strategies)
- [ ] Implement LSTM model
- [ ] Implement Random Forest model
- [ ] Set up MLflow for tracking
- [ ] Model evaluation framework

**Week 7: Backtesting**
- [ ] Implement backtesting engine
- [ ] Historical simulation
- [ ] Performance metrics calculation
- [ ] Strategy comparison
- [ ] Optimization

**Week 8: Model Deployment**
- [ ] Export models to ONNX
- [ ] Implement inference service
- [ ] Implement ensemble logic
- [ ] Model versioning
- [ ] A/B testing framework

### Phase 3: Risk Management (Weeks 9-10)

**Week 9: Risk Checks**
- [ ] Implement pre-trade risk checks
- [ ] Implement portfolio risk monitoring
- [ ] Implement position size limits
- [ ] Implement daily loss limits
- [ ] Risk alerting

**Week 10: Stop-Loss & Circuit Breakers**
- [ ] Implement automatic stop-loss
- [ ] Implement trailing stops
- [ ] Implement circuit breakers
- [ ] Emergency halt mechanism
- [ ] Risk reporting

### Phase 4: Dashboard & Monitoring (Weeks 11-12)

**Week 11: Dashboard Development**
- [ ] Set up React frontend
- [ ] Implement trading dashboard
- [ ] Implement performance charts
- [ ] Implement risk dashboard
- [ ] Real-time updates (WebSocket)

**Week 12: Monitoring Setup**
- [ ] Set up Prometheus
- [ ] Set up Grafana dashboards
- [ ] Configure alerting (Alertmanager)
- [ ] Set up logging (ELK stack)
- [ ] Distributed tracing (Jaeger)

### Phase 5: Testing & Security (Weeks 13-14)

**Week 13: Comprehensive Testing**
- [ ] Unit tests (80%+ coverage)
- [ ] Integration tests
- [ ] End-to-end tests
- [ ] Load testing (Locust)
- [ ] Chaos engineering tests

**Week 14: Security Hardening**
- [ ] Implement authentication
- [ ] Set up secrets management
- [ ] Security audit
- [ ] Penetration testing
- [ ] Compliance review

### Phase 6: Production Deployment (Weeks 15-16)

**Week 15: Infrastructure Setup**
- [ ] Set up AWS infrastructure (Terraform)
- [ ] Configure VPC and networking
- [ ] Set up RDS databases
- [ ] Set up ElastiCache Redis
- [ ] Set up ECS clusters

**Week 16: Go-Live**
- [ ] Deploy to staging environment
- [ ] Staging validation
- [ ] Deploy to production (paper trading)
- [ ] Monitoring and alerting verification
- [ ] Run parallel (paper + live monitoring)

### Phase 7: Live Trading (Week 17+)

**Week 17: Paper Trading Validation**
- [ ] Run paper trading for 2 weeks minimum
- [ ] Validate all strategies
- [ ] Monitor performance
- [ ] Fine-tune parameters
- [ ] Risk validation

**Week 18: Live Trading (Small Scale)**
- [ ] Start with small capital (£1,000-£5,000)
- [ ] Single strategy only
- [ ] Conservative risk limits
- [ ] Close monitoring
- [ ] Daily performance review

**Week 19+: Scale Up**
- [ ] Gradually increase capital
- [ ] Add more strategies
- [ ] Optimize performance
- [ ] Continuous improvement

---

## Cost Analysis

### Infrastructure Costs (AWS, Monthly)

**Compute (ECS Fargate):**
- Market Data Service: 2 tasks × $30 = $60
- AI/ML Service: 1 task × $40 = $40
- Order Service: 2 tasks × $30 = $60
- Position Service: 1 task × $25 = $25
- Risk Manager: 2 tasks × $30 = $60
- Dashboard: 1 task × $25 = $25
- **Subtotal:** $270/month

**Database:**
- RDS PostgreSQL (db.t3.medium): $80
- RDS TimescaleDB (db.t3.medium): $80
- ElastiCache Redis (cache.t3.medium): $60
- **Subtotal:** $220/month

**Storage:**
- S3 (100 GB): $3
- EBS volumes: $20
- **Subtotal:** $23/month

**Networking:**
- ALB: $20
- Data transfer: $10
- **Subtotal:** $30/month

**Monitoring:**
- CloudWatch: $15
- **Subtotal:** $15/month

**IB Gateway (EC2):**
- m5.large reserved instance: $50
- **Subtotal:** $50/month

**Total AWS Infrastructure:** ~$608/month

### Software & Services Costs (Monthly)

**Trading & Market Data:**
- Interactive Brokers: $0 (no platform fees)
- Financial Modeling Prep API: $19
- **Subtotal:** $19/month

**Optional Services:**
- PagerDuty (alerting): $19
- Auth0 (authentication): $0 (free tier)
- **Subtotal:** $19/month

### Total Monthly Operating Cost

**Development Environment:** ~$100/month (reduced infrastructure)
**Production Environment:** ~$646/month

**Annual Cost:** ~$7,752/year (production)

### Cost Optimization

**Potential Savings:**
1. **Reserved Instances:** 30-50% savings on EC2/RDS
2. **Spot Instances:** 70% savings for non-critical workloads
3. **Right-sizing:** Monitor and adjust instance sizes
4. **Self-Hosted Option:** ~$200/month with own server

**Self-Hosted (Single Server):**
- VPS (16 GB RAM, 8 vCPU): $80/month
- Market data API: $19/month
- **Total:** ~$99/month (~$1,200/year)

---

## Risks & Mitigations

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| IBKR API connection failure | Medium | High | Auto-reconnect, redundant connections, monitoring |
| Market data feed outage | Low | High | Multiple data providers, fallback mechanisms |
| Model prediction errors | Medium | Medium | Ensemble models, confidence thresholds, validation |
| Database failure | Low | High | Multi-AZ deployment, automated backups, read replicas |
| Message queue failure | Low | High | NATS JetStream persistence, redundancy |
| Service crashes | Medium | Medium | Health checks, auto-restart, error handling |

### Operational Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Incorrect order placement | Low | High | Comprehensive testing, pre-trade validation, position limits |
| Risk limit breach | Medium | High | Real-time monitoring, circuit breakers, automatic halt |
| Market volatility | High | Medium | Adaptive position sizing, stop-losses, max drawdown limits |
| Flash crash | Low | High | Circuit breakers, emergency halt, stop-losses |
| Regulatory changes | Low | Medium | Compliance monitoring, legal consultation, adaptability |
| Key personnel loss | Low | Medium | Documentation, knowledge sharing, redundancy |

### Financial Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Strategy underperformance | Medium | Medium | Continuous monitoring, multiple strategies, rebalancing |
| Large drawdown | Low | High | Risk limits, stop-losses, circuit breakers |
| Slippage exceeding expectations | Medium | Low | Limit orders, liquidity filters, execution quality monitoring |
| Broker failure | Very Low | High | FCA protection (£85k), diversify capital across brokers |
| Tax liabilities | High | Low | Accurate record keeping, tax calculation, professional advice |

---

## Appendices

### Appendix A: Glossary

**API (Application Programming Interface):** Interface for programmatic access
**Algo Trading:** Automated trading using algorithms
**Backtesting:** Testing strategy on historical data
**Circuit Breaker:** Emergency trading halt mechanism
**ECS (Elastic Container Service):** AWS container orchestration
**FCA (Financial Conduct Authority):** UK financial regulator
**HFT (High-Frequency Trading):** Very fast algorithmic trading
**IBKR:** Interactive Brokers
**IB Gateway:** Lightweight IBKR connection software
**MiFID II:** Markets in Financial Instruments Directive (EU regulation)
**ONNX:** Open Neural Network Exchange (model format)
**P&L (Profit and Loss):** Trading profit or loss
**RTO (Recovery Time Objective):** Target time to recover from disaster
**RPO (Recovery Point Objective):** Maximum acceptable data loss
**Sharpe Ratio:** Risk-adjusted return metric
**Slippage:** Difference between expected and actual execution price
**TWS (Trader Workstation):** IBKR desktop trading platform
**TWS API:** Interactive Brokers API

### Appendix B: References

**Interactive Brokers:**
- TWS API Documentation: https://www.interactivebrokers.com/en/trading/ib-api.php
- IB Gateway Download: https://www.interactivebrokers.com/en/index.php?f=16457
- FCA Register: https://register.fca.org.uk/s/firm?id=001b000000MfKjCAAV

**Financial Modeling Prep:**
- API Documentation: https://site.financialmodelingprep.com/developer/docs

**Python Libraries:**
- ibapi: https://github.com/InteractiveBrokers/tws-api-public
- FastAPI: https://fastapi.tiangolo.com/
- PyTorch: https://pytorch.org/

**Regulatory:**
- FCA Handbook: https://www.handbook.fca.org.uk/
- MiFID II: https://www.fca.org.uk/markets/mifid-ii

### Appendix C: Contact & Support

**Project Team:**
- System Architect: [TBD]
- Lead Developer: [TBD]
- Quantitative Analyst: [TBD]
- DevOps Engineer: [TBD]

**External Contacts:**
- Interactive Brokers Support: https://www.interactivebrokers.com/en/support
- AWS Support: [Enterprise Support Plan]

---

## Document Control

**Version History:**

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-11-13 | System | Initial HLD document |

**Review & Approval:**

| Role | Name | Date | Signature |
|------|------|------|-----------|
| System Architect | [TBD] | | |
| Lead Developer | [TBD] | | |
| CTO/Technical Lead | [TBD] | | |

**Next Review Date:** 2026-02-13 (3 months)

---

**END OF DOCUMENT**
