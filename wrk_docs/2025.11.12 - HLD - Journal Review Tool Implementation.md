# High-Level Design: Journal Review Tool (jrnrvw)

**Document Type:** High-Level Design (HLD)
**Version:** 1.0
**Date:** 2025.11.12
**Author:** System Design
**Status:** Draft
**Related Documents:** 2025.11.12 - Journal Review Tool Specification.md

---

## Table of Contents
1. [Executive Summary](#executive-summary)
2. [System Overview](#system-overview)
3. [Architecture Design](#architecture-design)
4. [Module Design](#module-design)
5. [Data Flow](#data-flow)
6. [Detailed Component Design](#detailed-component-design)
7. [Error Handling Strategy](#error-handling-strategy)
8. [Performance Considerations](#performance-considerations)
9. [Security Considerations](#security-considerations)
10. [Testing Strategy](#testing-strategy)
11. [Implementation Roadmap](#implementation-roadmap)
12. [Appendices](#appendices)

---

## Executive Summary

### Purpose
This document provides a comprehensive high-level design for `jrnrvw` (Journal Review Tool), a Rust-based CLI application that discovers, analyzes, and reports on task journal files across directory trees. The tool enables developers to gain insights into their work patterns by aggregating journal entries grouped by repository and task, with flexible time-range filtering.

### Goals
1. **Efficient Discovery**: Quickly scan directory trees to find journal files matching the pattern `yyyy.mm.dd - JRN - *.md`
2. **Intelligent Analysis**: Parse markdown content to extract tasks, activities, and metadata
3. **Flexible Reporting**: Generate reports in multiple formats (text, JSON, markdown, HTML)
4. **User Experience**: Provide intuitive CLI with helpful defaults and comprehensive options
5. **Performance**: Handle large codebases with thousands of journal files efficiently
6. **Extensibility**: Design for future enhancements (web UI, AI analysis, integrations)

### Key Features
- Recursive file system scanning with pattern matching
- Git repository boundary detection
- Multiple task identifier formats (GitHub, JIRA, custom)
- Time-range filtering (calendar and activity-based)
- Hierarchical grouping (Repository → Task → Entries)
- Multiple output formats with colored terminal support
- Statistical summaries and insights

### Non-Goals (Deferred to Future Versions)
- Web-based dashboard interface
- Real-time file watching and updates
- Journal file editing or creation
- Integration with external services (GitHub, JIRA APIs)
- AI-powered content analysis
- Multi-user collaboration features

---

## System Overview

### System Context Diagram

```
┌─────────────────────────────────────────────────────────────┐
│                        File System                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │  Repository  │  │  Repository  │  │  Repository  │     │
│  │      A       │  │      B       │  │      C       │     │
│  │              │  │              │  │              │     │
│  │ *.md files   │  │ *.md files   │  │ *.md files   │     │
│  │ .git/        │  │ .git/        │  │ .git/        │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
              ┌──────────────────────────┐
              │                          │
              │   jrnrvw CLI Tool        │
              │   (Rust Application)     │
              │                          │
              └──────────────────────────┘
                            │
                            ▼
              ┌──────────────────────────┐
              │   Output Destinations    │
              ├──────────────────────────┤
              │ • Terminal (stdout)      │
              │ • File (JSON/MD/HTML)    │
              │ • Pipe to other tools    │
              └──────────────────────────┘
```

### High-Level Architecture

```
┌───────────────────────────────────────────────────────────────┐
│                         CLI Layer                             │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  Argument Parser (clap)                                 │ │
│  │  - Command parsing                                      │ │
│  │  - Validation                                           │ │
│  │  - Help generation                                      │ │
│  └─────────────────────────────────────────────────────────┘ │
└───────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌───────────────────────────────────────────────────────────────┐
│                     Application Core                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │
│  │   Scanner    │→ │    Parser    │→ │   Analyzer   │       │
│  │   Module     │  │    Module    │  │    Module    │       │
│  └──────────────┘  └──────────────┘  └──────────────┘       │
│         │                 │                  │               │
│         ▼                 ▼                  ▼               │
│  ┌─────────────────────────────────────────────────┐        │
│  │         Shared Data Structures & Types          │        │
│  └─────────────────────────────────────────────────┘        │
└───────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌───────────────────────────────────────────────────────────────┐
│                      Output Layer                             │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │
│  │    Text      │  │     JSON     │  │   Markdown   │       │
│  │  Formatter   │  │  Formatter   │  │  Formatter   │       │
│  └──────────────┘  └──────────────┘  └──────────────┘       │
└───────────────────────────────────────────────────────────────┘
```

### Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| Language | Rust 2021 Edition | Performance, safety, excellent CLI ecosystem |
| CLI Framework | clap v4.5 | Argument parsing, help generation |
| Date/Time | chrono v0.4 | Date parsing and manipulation |
| File Walking | walkdir v2.5 | Efficient directory traversal |
| Markdown | pulldown-cmark v0.12 | Markdown parsing and AST |
| Pattern Matching | regex v1.10 | Task identifier extraction |
| Serialization | serde v1.0, serde_json v1.0 | JSON output |
| Terminal | colored v2.1 | Colored output |
| Error Handling | anyhow v1.0, thiserror v1.0 | Error management |
| Utilities | itertools v0.13 | Iterator extensions |

---

## Architecture Design

### Layered Architecture

The application follows a clean layered architecture with clear separation of concerns:

```
┌─────────────────────────────────────────────────────────┐
│  Layer 1: Presentation (CLI & Output)                   │
│  - User interaction                                     │
│  - Output formatting                                    │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│  Layer 2: Application Logic                            │
│  - Business rules                                       │
│  - Orchestration                                        │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│  Layer 3: Domain Services                               │
│  - Scanner, Parser, Analyzer                            │
│  - Core algorithms                                      │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│  Layer 4: Data & Infrastructure                         │
│  - File system access                                   │
│  - Data structures                                      │
└─────────────────────────────────────────────────────────┘
```

### Module Organization

```
jrnrvw/
├── Cargo.toml
├── README.md
├── LICENSE
├── src/
│   ├── main.rs              # Application entry point
│   ├── lib.rs               # Library root
│   │
│   ├── cli/
│   │   ├── mod.rs           # CLI module root
│   │   ├── args.rs          # Argument definitions (clap)
│   │   └── commands.rs      # Command handlers
│   │
│   ├── scanner/
│   │   ├── mod.rs           # Scanner module root
│   │   ├── walker.rs        # Directory walking logic
│   │   ├── matcher.rs       # File pattern matching
│   │   └── repo_detector.rs # Repository detection
│   │
│   ├── parser/
│   │   ├── mod.rs           # Parser module root
│   │   ├── journal.rs       # Journal file parsing
│   │   ├── markdown.rs      # Markdown processing
│   │   ├── task_extractor.rs # Task identifier extraction
│   │   └── activity_extractor.rs # Activity extraction
│   │
│   ├── analyzer/
│   │   ├── mod.rs           # Analyzer module root
│   │   ├── grouper.rs       # Grouping logic
│   │   ├── filter.rs        # Date range filtering
│   │   ├── statistics.rs    # Statistical calculations
│   │   └── sorter.rs        # Sorting algorithms
│   │
│   ├── formatter/
│   │   ├── mod.rs           # Formatter module root
│   │   ├── text.rs          # Text output formatter
│   │   ├── json.rs          # JSON output formatter
│   │   ├── markdown.rs      # Markdown report formatter
│   │   └── tree_renderer.rs # Tree structure rendering
│   │
│   ├── models/
│   │   ├── mod.rs           # Models module root
│   │   ├── journal.rs       # Journal data structures
│   │   ├── repository.rs    # Repository models
│   │   ├── task.rs          # Task models
│   │   ├── analysis.rs      # Analysis result models
│   │   └── config.rs        # Configuration models
│   │
│   └── utils/
│       ├── mod.rs           # Utils module root
│       ├── date.rs          # Date utilities
│       ├── path.rs          # Path utilities
│       └── error.rs         # Custom error types
│
├── tests/
│   ├── integration/         # Integration tests
│   │   ├── mod.rs
│   │   ├── scanner_tests.rs
│   │   ├── analyzer_tests.rs
│   │   └── end_to_end_tests.rs
│   │
│   └── fixtures/            # Test data
│       ├── repo_a/
│       │   ├── .git/
│       │   └── 2025.11.01 - JRN - test.md
│       └── repo_b/
│           └── ...
│
└── benches/                 # Performance benchmarks
    └── scanner_bench.rs
```

---

## Module Design

### 1. CLI Module (`cli/`)

**Responsibility**: Handle user interaction, parse command-line arguments, validate input, and coordinate application flow.

#### Components

##### 1.1 Argument Parser (`args.rs`)

```rust
use clap::{Parser, Subcommand, ValueEnum};

#[derive(Parser)]
#[command(name = "jrnrvw")]
#[command(author, version, about, long_about = None)]
pub struct Cli {
    /// Root directory to search (default: current directory)
    #[arg(short, long, value_name = "PATH")]
    pub path: Option<PathBuf>,

    /// Maximum directory depth to search
    #[arg(long, value_name = "DEPTH")]
    pub max_depth: Option<usize>,

    /// Date range filtering
    #[command(flatten)]
    pub date_filter: DateFilter,

    /// Grouping options
    #[command(flatten)]
    pub grouping: GroupingOptions,

    /// Output options
    #[command(flatten)]
    pub output: OutputOptions,

    /// Filter by repository name
    #[arg(long, value_name = "REPO")]
    pub repo: Option<String>,

    /// Filter by task identifier
    #[arg(long, value_name = "TASK")]
    pub task: Option<String>,

    /// Enable verbose output
    #[arg(short, long)]
    pub verbose: bool,
}

#[derive(Args)]
#[group(multiple = false)]
pub struct DateFilter {
    /// Last 7 calendar days
    #[arg(long)]
    pub last_week: bool,

    /// Last 30 calendar days
    #[arg(long)]
    pub last_month: bool,

    /// Last N calendar days
    #[arg(long, value_name = "N")]
    pub last_n_days: Option<u32>,

    /// Last N days with journal entries
    #[arg(long, value_name = "N")]
    pub last_n_active_days: Option<u32>,

    /// Current week (Monday-Sunday)
    #[arg(long)]
    pub this_week: bool,

    /// Current calendar month
    #[arg(long)]
    pub this_month: bool,

    /// Start date (yyyy-mm-dd)
    #[arg(long, value_name = "DATE")]
    pub from: Option<NaiveDate>,

    /// End date (yyyy-mm-dd)
    #[arg(long, value_name = "DATE")]
    pub to: Option<NaiveDate>,

    /// Specific date (yyyy-mm-dd)
    #[arg(long, value_name = "DATE")]
    pub date: Option<NaiveDate>,
}

#[derive(Args)]
pub struct GroupingOptions {
    /// Grouping mode
    #[arg(long, value_enum, default_value = "repo-task")]
    pub group_by: GroupMode,

    /// Hide entries without task identifiers
    #[arg(long)]
    pub no_ungrouped: bool,

    /// Merge similar task identifiers
    #[arg(long)]
    pub merge_tasks: bool,
}

#[derive(ValueEnum, Clone)]
pub enum GroupMode {
    RepoTask,
    Repo,
    Task,
    Date,
}

#[derive(Args)]
pub struct OutputOptions {
    /// Output format
    #[arg(short, long, value_enum, default_value = "text")]
    pub output: OutputFormat,

    /// Write output to file
    #[arg(short, long, value_name = "FILE")]
    pub file: Option<PathBuf>,

    /// Show summary statistics only
    #[arg(long)]
    pub summary: bool,

    /// Include full journal content
    #[arg(long)]
    pub verbose: bool,

    /// Minimal output
    #[arg(short, long)]
    pub quiet: bool,

    /// Disable colored output
    #[arg(long)]
    pub no_color: bool,

    /// Sort field
    #[arg(long, value_enum, default_value = "date")]
    pub sort: SortField,

    /// Reverse sort order
    #[arg(long)]
    pub reverse: bool,

    /// Limit number of entries
    #[arg(long, value_name = "N")]
    pub limit: Option<usize>,

    /// Show file paths
    #[arg(long)]
    pub show_paths: bool,
}

#[derive(ValueEnum, Clone)]
pub enum OutputFormat {
    Text,
    Json,
    Markdown,
    Html,
}

#[derive(ValueEnum, Clone)]
pub enum SortField {
    Date,
    Repo,
    Task,
    Activity,
}
```

##### 1.2 Command Handler (`commands.rs`)

```rust
pub struct CommandExecutor {
    cli: Cli,
}

impl CommandExecutor {
    pub fn new(cli: Cli) -> Self {
        Self { cli }
    }

    pub fn execute(&self) -> Result<()> {
        // 1. Build configuration from CLI args
        let config = self.build_config()?;

        // 2. Scan for journal files
        let files = self.scan_journals(&config)?;

        // 3. Parse journal files
        let entries = self.parse_journals(files, &config)?;

        // 4. Filter by date range
        let filtered = self.filter_entries(entries, &config)?;

        // 5. Analyze and group
        let analysis = self.analyze(filtered, &config)?;

        // 6. Format and output
        self.output_results(analysis, &config)?;

        Ok(())
    }

    fn build_config(&self) -> Result<Config> {
        // Convert CLI args to internal config
        Config::from_cli(&self.cli)
    }

    fn scan_journals(&self, config: &Config) -> Result<Vec<JournalFile>> {
        let scanner = Scanner::new(config.scan_config.clone());
        scanner.scan(&config.root_path)
    }

    fn parse_journals(
        &self,
        files: Vec<JournalFile>,
        config: &Config
    ) -> Result<Vec<JournalEntry>> {
        let parser = Parser::new(config.parse_config.clone());
        files.into_iter()
            .map(|f| parser.parse(f))
            .collect()
    }

    fn filter_entries(
        &self,
        entries: Vec<JournalEntry>,
        config: &Config
    ) -> Result<Vec<JournalEntry>> {
        let filter = Filter::new(config.filter_config.clone());
        filter.apply(entries)
    }

    fn analyze(
        &self,
        entries: Vec<JournalEntry>,
        config: &Config
    ) -> Result<AnalysisResult> {
        let analyzer = Analyzer::new(config.analyzer_config.clone());
        analyzer.analyze(entries)
    }

    fn output_results(
        &self,
        analysis: AnalysisResult,
        config: &Config
    ) -> Result<()> {
        let formatter = FormatterFactory::create(
            &config.output_format,
            config.format_options.clone()
        );

        let output = formatter.format(&analysis)?;

        if let Some(file_path) = &config.output_file {
            fs::write(file_path, output)?;
        } else {
            println!("{}", output);
        }

        Ok(())
    }
}
```

---

### 2. Scanner Module (`scanner/`)

**Responsibility**: Discover journal files in the file system and detect repository boundaries.

#### Components

##### 2.1 Directory Walker (`walker.rs`)

```rust
use walkdir::{WalkDir, DirEntry};

pub struct DirectoryWalker {
    config: ScanConfig,
}

#[derive(Clone)]
pub struct ScanConfig {
    pub max_depth: Option<usize>,
    pub follow_links: bool,
    pub include_hidden: bool,
}

impl DirectoryWalker {
    pub fn new(config: ScanConfig) -> Self {
        Self { config }
    }

    pub fn walk(&self, root: &Path) -> Result<Vec<DirEntry>> {
        let mut walker = WalkDir::new(root);

        if let Some(depth) = self.config.max_depth {
            walker = walker.max_depth(depth);
        }

        if self.config.follow_links {
            walker = walker.follow_links(true);
        }

        let entries: Result<Vec<_>> = walker
            .into_iter()
            .filter_entry(|e| self.should_include(e))
            .filter_map(|e| e.ok())
            .filter(|e| e.file_type().is_file())
            .collect();

        entries.context("Failed to walk directory")
    }

    fn should_include(&self, entry: &DirEntry) -> bool {
        // Skip hidden directories unless configured
        if !self.config.include_hidden && is_hidden(entry) {
            return false;
        }

        // Always skip .git internals (but not the .git directory itself)
        if entry.depth() > 1 && is_git_internal(entry) {
            return false;
        }

        true
    }
}

fn is_hidden(entry: &DirEntry) -> bool {
    entry.file_name()
        .to_str()
        .map(|s| s.starts_with('.') && s != ".git")
        .unwrap_or(false)
}

fn is_git_internal(entry: &DirEntry) -> bool {
    entry.path()
        .components()
        .any(|c| c.as_os_str() == ".git")
}
```

##### 2.2 File Matcher (`matcher.rs`)

```rust
use regex::Regex;
use chrono::NaiveDate;

pub struct FileMatcher {
    pattern: Regex,
}

impl FileMatcher {
    pub fn new() -> Self {
        // Pattern: yyyy.mm.dd - JRN - <description>.md
        let pattern = Regex::new(
            r"^(\d{4})\.(\d{2})\.(\d{2})\s*-\s*JRN\s*-\s*(.+)\.md$"
        ).unwrap();

        Self { pattern }
    }

    pub fn is_journal_file(&self, path: &Path) -> bool {
        path.file_name()
            .and_then(|n| n.to_str())
            .map(|name| self.pattern.is_match(name))
            .unwrap_or(false)
    }

    pub fn parse_journal_filename(&self, path: &Path) -> Option<JournalFileInfo> {
        let filename = path.file_name()?.to_str()?;

        let captures = self.pattern.captures(filename)?;

        let year: i32 = captures.get(1)?.as_str().parse().ok()?;
        let month: u32 = captures.get(2)?.as_str().parse().ok()?;
        let day: u32 = captures.get(3)?.as_str().parse().ok()?;
        let description = captures.get(4)?.as_str().to_string();

        let date = NaiveDate::from_ymd_opt(year, month, day)?;

        Some(JournalFileInfo {
            path: path.to_path_buf(),
            date,
            description,
        })
    }
}

#[derive(Debug, Clone)]
pub struct JournalFileInfo {
    pub path: PathBuf,
    pub date: NaiveDate,
    pub description: String,
}
```

##### 2.3 Repository Detector (`repo_detector.rs`)

```rust
use std::collections::HashMap;

pub struct RepositoryDetector {
    cache: HashMap<PathBuf, Option<Repository>>,
}

impl RepositoryDetector {
    pub fn new() -> Self {
        Self {
            cache: HashMap::new(),
        }
    }

    pub fn detect_repository(&mut self, file_path: &Path) -> Option<Repository> {
        // Check cache first
        let mut current = file_path.parent()?;

        // Check if we've already detected this repo
        if let Some(cached) = self.cache.get(current) {
            return cached.clone();
        }

        // Walk up the directory tree looking for .git
        while let Some(dir) = current.parent() {
            let git_dir = current.join(".git");

            if git_dir.exists() && git_dir.is_dir() {
                let repo = self.create_repository(current);
                // Cache for all subdirectories
                self.cache.insert(current.to_path_buf(), repo.clone());
                return repo;
            }

            current = dir;
        }

        // No repository found
        self.cache.insert(file_path.to_path_buf(), None);
        None
    }

    fn create_repository(&self, repo_root: &Path) -> Option<Repository> {
        let name = self.extract_repo_name(repo_root)?;
        let remote = self.extract_remote_url(repo_root);

        Some(Repository {
            name,
            path: repo_root.to_path_buf(),
            remote,
        })
    }

    fn extract_repo_name(&self, repo_root: &Path) -> Option<String> {
        // Try git config first
        if let Ok(name) = self.read_git_config_name(repo_root) {
            return Some(name);
        }

        // Fall back to directory name
        repo_root.file_name()
            .and_then(|n| n.to_str())
            .map(|s| s.to_string())
    }

    fn read_git_config_name(&self, repo_root: &Path) -> Result<String> {
        // Read from .git/config
        let config_path = repo_root.join(".git/config");
        let content = fs::read_to_string(config_path)?;

        // Parse [remote "origin"] url
        // Extract repo name from URL
        // This is simplified - use git2 crate for production

        Ok(self.parse_repo_name_from_config(&content)?)
    }

    fn extract_remote_url(&self, repo_root: &Path) -> Option<String> {
        // Similar logic to read remote URL from git config
        None // Simplified for now
    }
}
```

##### 2.4 Scanner Orchestrator (`mod.rs`)

```rust
pub struct Scanner {
    walker: DirectoryWalker,
    matcher: FileMatcher,
    repo_detector: RepositoryDetector,
}

impl Scanner {
    pub fn new(config: ScanConfig) -> Self {
        Self {
            walker: DirectoryWalker::new(config),
            matcher: FileMatcher::new(),
            repo_detector: RepositoryDetector::new(),
        }
    }

    pub fn scan(&mut self, root: &Path) -> Result<Vec<JournalFile>> {
        // Walk directory tree
        let entries = self.walker.walk(root)?;

        // Filter and parse journal files
        let mut journals = Vec::new();

        for entry in entries {
            let path = entry.path();

            if !self.matcher.is_journal_file(path) {
                continue;
            }

            if let Some(info) = self.matcher.parse_journal_filename(path) {
                let repository = self.repo_detector.detect_repository(path);

                journals.push(JournalFile {
                    path: info.path,
                    date: info.date,
                    description: info.description,
                    repository,
                });
            }
        }

        // Sort by date
        journals.sort_by_key(|j| j.date);

        Ok(journals)
    }
}
```

---

### 3. Parser Module (`parser/`)

**Responsibility**: Parse journal files, extract markdown structure, identify tasks, and extract activities.

#### Components

##### 3.1 Journal Parser (`journal.rs`)

```rust
use pulldown_cmark::{Parser as MdParser, Event, Tag};

pub struct JournalParser {
    task_extractor: TaskExtractor,
    activity_extractor: ActivityExtractor,
}

impl JournalParser {
    pub fn new() -> Self {
        Self {
            task_extractor: TaskExtractor::new(),
            activity_extractor: ActivityExtractor::new(),
        }
    }

    pub fn parse(&self, file: JournalFile) -> Result<JournalEntry> {
        // Read file content
        let content = fs::read_to_string(&file.path)
            .context("Failed to read journal file")?;

        // Parse markdown
        let md_events = self.parse_markdown(&content);

        // Extract tasks
        let tasks = self.task_extractor.extract(&content, &md_events);

        // Extract activities
        let activities = self.activity_extractor.extract(&content, &md_events);

        Ok(JournalEntry {
            file,
            tasks,
            activities,
            content,
        })
    }

    fn parse_markdown(&self, content: &str) -> Vec<Event> {
        MdParser::new(content).collect()
    }
}
```

##### 3.2 Task Extractor (`task_extractor.rs`)

```rust
use regex::Regex;

pub struct TaskExtractor {
    github_pattern: Regex,
    jira_pattern: Regex,
    custom_patterns: Vec<Regex>,
}

impl TaskExtractor {
    pub fn new() -> Self {
        Self {
            github_pattern: Regex::new(r"#(\d+)").unwrap(),
            jira_pattern: Regex::new(r"\b([A-Z]+-\d+)\b").unwrap(),
            custom_patterns: vec![
                Regex::new(r"\[([A-Z]+-\d+)\]").unwrap(),
                Regex::new(r"TASK-(\d+)").unwrap(),
            ],
        }
    }

    pub fn extract(&self, content: &str, events: &[Event]) -> Vec<TaskReference> {
        let mut tasks = Vec::new();

        // Extract from headings first
        tasks.extend(self.extract_from_headings(events));

        // Extract GitHub issue references
        tasks.extend(self.extract_github_issues(content));

        // Extract JIRA references
        tasks.extend(self.extract_jira_issues(content));

        // Extract custom patterns
        tasks.extend(self.extract_custom_patterns(content));

        // Deduplicate
        self.deduplicate(tasks)
    }

    fn extract_from_headings(&self, events: &[Event]) -> Vec<TaskReference> {
        let mut tasks = Vec::new();
        let mut in_heading = false;
        let mut heading_text = String::new();

        for event in events {
            match event {
                Event::Start(Tag::Heading(_, _, _)) => {
                    in_heading = true;
                    heading_text.clear();
                }
                Event::Text(text) if in_heading => {
                    heading_text.push_str(text);
                }
                Event::End(Tag::Heading(_, _, _)) => {
                    if heading_text.to_lowercase().starts_with("task") {
                        tasks.push(TaskReference {
                            id: self.generate_task_id(&heading_text),
                            title: Some(heading_text.clone()),
                            task_type: TaskType::Heading(heading_text.clone()),
                        });
                    }
                    in_heading = false;
                }
                _ => {}
            }
        }

        tasks
    }

    fn extract_github_issues(&self, content: &str) -> Vec<TaskReference> {
        self.github_pattern
            .captures_iter(content)
            .map(|cap| {
                let issue_num: u32 = cap[1].parse().unwrap();
                TaskReference {
                    id: format!("#{}", issue_num),
                    title: None,
                    task_type: TaskType::GitHub(issue_num),
                }
            })
            .collect()
    }

    fn extract_jira_issues(&self, content: &str) -> Vec<TaskReference> {
        self.jira_pattern
            .captures_iter(content)
            .map(|cap| {
                let issue_id = cap[1].to_string();
                TaskReference {
                    id: issue_id.clone(),
                    title: None,
                    task_type: TaskType::Jira(issue_id),
                }
            })
            .collect()
    }

    fn extract_custom_patterns(&self, content: &str) -> Vec<TaskReference> {
        let mut tasks = Vec::new();

        for pattern in &self.custom_patterns {
            for cap in pattern.captures_iter(content) {
                let task_id = cap[1].to_string();
                tasks.push(TaskReference {
                    id: task_id.clone(),
                    title: None,
                    task_type: TaskType::Custom(task_id),
                });
            }
        }

        tasks
    }

    fn deduplicate(&self, tasks: Vec<TaskReference>) -> Vec<TaskReference> {
        let mut seen = std::collections::HashSet::new();
        tasks.into_iter()
            .filter(|t| seen.insert(t.id.clone()))
            .collect()
    }

    fn generate_task_id(&self, heading: &str) -> String {
        // Generate ID from heading text
        heading
            .trim()
            .replace(" ", "-")
            .to_lowercase()
    }
}
```

##### 3.3 Activity Extractor (`activity_extractor.rs`)

```rust
pub struct ActivityExtractor;

impl ActivityExtractor {
    pub fn new() -> Self {
        Self
    }

    pub fn extract(&self, content: &str, events: &[Event]) -> Vec<Activity> {
        let mut activities = Vec::new();

        // Extract from list items
        activities.extend(self.extract_from_lists(events));

        // Extract from paragraphs
        activities.extend(self.extract_from_paragraphs(events));

        activities
    }

    fn extract_from_lists(&self, events: &[Event]) -> Vec<Activity> {
        let mut activities = Vec::new();
        let mut in_list_item = false;
        let mut item_text = String::new();

        for event in events {
            match event {
                Event::Start(Tag::Item) => {
                    in_list_item = true;
                    item_text.clear();
                }
                Event::Text(text) if in_list_item => {
                    item_text.push_str(text);
                }
                Event::End(Tag::Item) => {
                    if !item_text.trim().is_empty() {
                        activities.push(Activity {
                            description: item_text.trim().to_string(),
                            task: None, // Will be associated later
                        });
                    }
                    in_list_item = false;
                }
                _ => {}
            }
        }

        activities
    }

    fn extract_from_paragraphs(&self, events: &[Event]) -> Vec<Activity> {
        // Similar logic for paragraphs
        Vec::new()
    }
}
```

---

### 4. Analyzer Module (`analyzer/`)

**Responsibility**: Group, filter, sort, and compute statistics on journal entries.

#### Components

##### 4.1 Grouper (`grouper.rs`)

```rust
pub struct Grouper {
    config: GroupingConfig,
}

#[derive(Clone)]
pub struct GroupingConfig {
    pub mode: GroupMode,
    pub merge_similar: bool,
    pub include_ungrouped: bool,
}

impl Grouper {
    pub fn new(config: GroupingConfig) -> Self {
        Self { config }
    }

    pub fn group(&self, entries: Vec<JournalEntry>) -> AnalysisResult {
        match self.config.mode {
            GroupMode::RepoTask => self.group_by_repo_and_task(entries),
            GroupMode::Repo => self.group_by_repo(entries),
            GroupMode::Task => self.group_by_task(entries),
            GroupMode::Date => self.group_by_date(entries),
        }
    }

    fn group_by_repo_and_task(&self, entries: Vec<JournalEntry>) -> AnalysisResult {
        let mut repo_groups: HashMap<String, Vec<JournalEntry>> = HashMap::new();

        // First group by repository
        for entry in entries {
            let repo_key = entry.file.repository
                .as_ref()
                .map(|r| r.name.clone())
                .unwrap_or_else(|| "ungrouped".to_string());

            repo_groups.entry(repo_key)
                .or_insert_with(Vec::new)
                .push(entry);
        }

        // Then group each repo by task
        let repositories: Vec<RepositoryAnalysis> = repo_groups
            .into_iter()
            .map(|(repo_name, repo_entries)| {
                self.create_repository_analysis(repo_name, repo_entries)
            })
            .collect();

        AnalysisResult {
            repositories,
            summary: self.compute_summary(&repositories),
        }
    }

    fn create_repository_analysis(
        &self,
        repo_name: String,
        entries: Vec<JournalEntry>
    ) -> RepositoryAnalysis {
        let mut task_groups: HashMap<String, Vec<JournalEntry>> = HashMap::new();
        let mut ungrouped = Vec::new();

        for entry in entries {
            if entry.tasks.is_empty() {
                ungrouped.push(entry);
            } else {
                for task in &entry.tasks {
                    task_groups.entry(task.id.clone())
                        .or_insert_with(Vec::new)
                        .push(entry.clone());
                }
            }
        }

        let task_groups: Vec<TaskGroup> = task_groups
            .into_iter()
            .map(|(task_id, journals)| {
                TaskGroup {
                    task: journals[0].tasks.iter()
                        .find(|t| t.id == task_id)
                        .cloned()
                        .unwrap(),
                    journals,
                }
            })
            .collect();

        // Get repository info from first entry
        let repository = ungrouped.first()
            .or_else(|| task_groups.first()?.journals.first())
            .and_then(|e| e.file.repository.clone())
            .unwrap_or_else(|| Repository {
                name: repo_name.clone(),
                path: PathBuf::new(),
                remote: None,
            });

        RepositoryAnalysis {
            repository,
            task_groups,
            ungrouped,
        }
    }

    fn compute_summary(&self, repositories: &[RepositoryAnalysis]) -> Summary {
        let total_journals: usize = repositories.iter()
            .map(|r| r.task_groups.iter().map(|tg| tg.journals.len()).sum::<usize>()
                + r.ungrouped.len())
            .sum();

        let total_tasks: usize = repositories.iter()
            .map(|r| r.task_groups.len())
            .sum();

        // Collect all dates
        let mut all_dates: Vec<NaiveDate> = Vec::new();
        for repo in repositories {
            for tg in &repo.task_groups {
                for journal in &tg.journals {
                    all_dates.push(journal.file.date);
                }
            }
            for journal in &repo.ungrouped {
                all_dates.push(journal.file.date);
            }
        }

        all_dates.sort();
        all_dates.dedup();

        let date_range = if let (Some(&first), Some(&last)) =
            (all_dates.first(), all_dates.last()) {
            DateRange { from: first, to: last }
        } else {
            DateRange {
                from: chrono::Local::now().date_naive(),
                to: chrono::Local::now().date_naive(),
            }
        };

        // Find most active day
        let mut date_counts: HashMap<NaiveDate, usize> = HashMap::new();
        for date in &all_dates {
            *date_counts.entry(*date).or_insert(0) += 1;
        }

        let most_active_day = date_counts.into_iter()
            .max_by_key(|(_, count)| *count);

        Summary {
            date_range,
            total_journals,
            total_repositories: repositories.len(),
            total_tasks,
            active_days: all_dates.len(),
            most_active_day,
        }
    }
}
```

##### 4.2 Filter (`filter.rs`)

```rust
pub struct Filter {
    config: FilterConfig,
}

#[derive(Clone)]
pub struct FilterConfig {
    pub date_range: Option<DateRange>,
    pub active_days_mode: bool,
    pub repo_filter: Option<String>,
    pub task_filter: Option<String>,
}

impl Filter {
    pub fn new(config: FilterConfig) -> Self {
        Self { config }
    }

    pub fn apply(&self, entries: Vec<JournalEntry>) -> Result<Vec<JournalEntry>> {
        let mut filtered = entries;

        // Apply date range filter
        if let Some(range) = &self.config.date_range {
            filtered = self.filter_by_date_range(filtered, range);
        }

        // Apply active days filter
        if self.config.active_days_mode {
            filtered = self.filter_by_active_days(filtered);
        }

        // Apply repository filter
        if let Some(repo) = &self.config.repo_filter {
            filtered = self.filter_by_repo(filtered, repo);
        }

        // Apply task filter
        if let Some(task) = &self.config.task_filter {
            filtered = self.filter_by_task(filtered, task);
        }

        Ok(filtered)
    }

    fn filter_by_date_range(
        &self,
        entries: Vec<JournalEntry>,
        range: &DateRange
    ) -> Vec<JournalEntry> {
        entries.into_iter()
            .filter(|e| e.file.date >= range.from && e.file.date <= range.to)
            .collect()
    }

    fn filter_by_active_days(&self, entries: Vec<JournalEntry>) -> Vec<JournalEntry> {
        // Get unique dates
        let mut dates: Vec<NaiveDate> = entries.iter()
            .map(|e| e.file.date)
            .collect();
        dates.sort();
        dates.dedup();

        // Keep entries from those dates
        let date_set: HashSet<_> = dates.into_iter().collect();
        entries.into_iter()
            .filter(|e| date_set.contains(&e.file.date))
            .collect()
    }

    fn filter_by_repo(&self, entries: Vec<JournalEntry>, repo: &str) -> Vec<JournalEntry> {
        entries.into_iter()
            .filter(|e| {
                e.file.repository
                    .as_ref()
                    .map(|r| r.name.contains(repo))
                    .unwrap_or(false)
            })
            .collect()
    }

    fn filter_by_task(&self, entries: Vec<JournalEntry>, task: &str) -> Vec<JournalEntry> {
        entries.into_iter()
            .filter(|e| e.tasks.iter().any(|t| t.id.contains(task)))
            .collect()
    }
}
```

---

### 5. Formatter Module (`formatter/`)

**Responsibility**: Format analysis results into various output formats.

##### 5.1 Text Formatter (`text.rs`)

```rust
use colored::*;

pub struct TextFormatter {
    options: FormatOptions,
}

pub struct FormatOptions {
    pub color_enabled: bool,
    pub show_paths: bool,
    pub verbose: bool,
    pub show_summary: bool,
}

impl TextFormatter {
    pub fn new(options: FormatOptions) -> Self {
        Self { options }
    }

    pub fn format(&self, analysis: &AnalysisResult) -> String {
        let mut output = String::new();

        // Format repositories
        for repo in &analysis.repositories {
            output.push_str(&self.format_repository(repo));
            output.push('\n');
        }

        // Format summary
        if self.options.show_summary {
            output.push_str(&self.format_summary(&analysis.summary));
        }

        output
    }

    fn format_repository(&self, repo: &RepositoryAnalysis) -> String {
        let mut output = String::new();

        let repo_name = if self.options.color_enabled {
            format!("Repository: {}", repo.repository.name.cyan().bold())
        } else {
            format!("Repository: {}", repo.repository.name)
        };

        output.push_str(&repo_name);
        output.push('\n');

        // Format task groups
        for (idx, task_group) in repo.task_groups.iter().enumerate() {
            let is_last_task = idx == repo.task_groups.len() - 1 && repo.ungrouped.is_empty();
            output.push_str(&self.format_task_group(task_group, is_last_task));
        }

        // Format ungrouped
        if !repo.ungrouped.is_empty() {
            output.push_str(&self.format_ungrouped(&repo.ungrouped));
        }

        output
    }

    fn format_task_group(&self, task_group: &TaskGroup, is_last: bool) -> String {
        let mut output = String::new();

        let prefix = if is_last { "└──" } else { "├──" };
        let task_line = format!(
            "{} Task: {}",
            prefix,
            self.format_task(&task_group.task)
        );

        output.push_str(&task_line);
        output.push('\n');

        // Format journals
        for (jdx, journal) in task_group.journals.iter().enumerate() {
            let is_last_journal = jdx == task_group.journals.len() - 1;
            let journal_prefix = if is_last {
                if is_last_journal { "    └──" } else { "    ├──" }
            } else {
                if is_last_journal { "│   └──" } else { "│   ├──" }
            };

            output.push_str(&self.format_journal(journal, journal_prefix));
        }

        output
    }

    fn format_task(&self, task: &TaskReference) -> String {
        let task_str = if let Some(title) = &task.title {
            format!("{} - {}", task.id, title)
        } else {
            task.id.clone()
        };

        if self.options.color_enabled {
            task_str.yellow().to_string()
        } else {
            task_str
        }
    }

    fn format_journal(&self, journal: &JournalEntry, prefix: &str) -> String {
        let mut output = String::new();

        let date_str = journal.file.date.format("%Y.%m.%d").to_string();
        let date_colored = if self.options.color_enabled {
            date_str.green().to_string()
        } else {
            date_str
        };

        let filename = format!(
            "{} - JRN - {}.md",
            date_colored,
            journal.file.description
        );

        output.push_str(&format!("{} {}\n", prefix, filename));

        // Show path if requested
        if self.options.show_paths {
            let path_str = format!("    Path: {}", journal.file.path.display());
            output.push_str(&path_str);
            output.push('\n');
        }

        // Show activities
        if !journal.activities.is_empty() {
            for activity in &journal.activities {
                let activity_line = format!("{}     • {}", prefix.chars().next().unwrap(), activity.description);
                output.push_str(&activity_line);
                output.push('\n');
            }
        }

        output
    }

    fn format_summary(&self, summary: &Summary) -> String {
        format!(
            "\nSummary:\n\
             - Total Journals: {}\n\
             - Date Range: {} - {}\n\
             - Repositories: {}\n\
             - Tasks: {}\n\
             - Active Days: {}\n",
            summary.total_journals,
            summary.date_range.from,
            summary.date_range.to,
            summary.total_repositories,
            summary.total_tasks,
            summary.active_days
        )
    }
}
```

##### 5.2 JSON Formatter (`json.rs`)

```rust
use serde_json;

pub struct JsonFormatter;

impl JsonFormatter {
    pub fn new() -> Self {
        Self
    }

    pub fn format(&self, analysis: &AnalysisResult) -> Result<String> {
        let json = serde_json::to_string_pretty(analysis)
            .context("Failed to serialize to JSON")?;
        Ok(json)
    }
}
```

---

## Data Flow

### End-to-End Data Flow Diagram

```
┌──────────────┐
│ User Input   │
│ (CLI Args)   │
└──────┬───────┘
       │
       ▼
┌──────────────────────┐
│ Argument Parsing     │
│ (clap)               │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Configuration        │
│ Building             │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────────────┐
│ Scanner Module               │
│ ┌──────────────────────────┐ │
│ │ 1. Walk Directory Tree   │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 2. Match Journal Files   │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 3. Detect Repositories   │ │
│ └──────────┬───────────────┘ │
└────────────┼─────────────────┘
             │
             ▼ Vec<JournalFile>
┌──────────────────────────────┐
│ Parser Module                │
│ ┌──────────────────────────┐ │
│ │ 1. Read File Content     │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 2. Parse Markdown        │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 3. Extract Tasks         │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 4. Extract Activities    │ │
│ └──────────┬───────────────┘ │
└────────────┼─────────────────┘
             │
             ▼ Vec<JournalEntry>
┌──────────────────────────────┐
│ Filter Module                │
│ ┌──────────────────────────┐ │
│ │ 1. Date Range Filter     │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 2. Active Days Filter    │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 3. Repo/Task Filter      │ │
│ └──────────┬───────────────┘ │
└────────────┼─────────────────┘
             │
             ▼ Vec<JournalEntry> (filtered)
┌──────────────────────────────┐
│ Analyzer Module              │
│ ┌──────────────────────────┐ │
│ │ 1. Group by Mode         │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 2. Sort                  │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ 3. Compute Statistics    │ │
│ └──────────┬───────────────┘ │
└────────────┼─────────────────┘
             │
             ▼ AnalysisResult
┌──────────────────────────────┐
│ Formatter Module             │
│ ┌──────────────────────────┐ │
│ │ Select Formatter         │ │
│ │ (Text/JSON/Markdown)     │ │
│ └──────────┬───────────────┘ │
│            ▼                 │
│ ┌──────────────────────────┐ │
│ │ Format Output            │ │
│ └──────────┬───────────────┘ │
└────────────┼─────────────────┘
             │
             ▼ String
┌──────────────────────────────┐
│ Output                       │
│ (stdout or file)             │
└──────────────────────────────┘
```

---

## Error Handling Strategy

### Error Types

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum JrnrvwError {
    #[error("Failed to scan directory: {0}")]
    ScanError(#[from] walkdir::Error),

    #[error("Failed to read journal file '{path}': {source}")]
    FileReadError {
        path: PathBuf,
        source: std::io::Error,
    },

    #[error("Invalid date format in filename: {0}")]
    InvalidDateFormat(String),

    #[error("Failed to parse markdown: {0}")]
    MarkdownParseError(String),

    #[error("Invalid date range: {0}")]
    InvalidDateRange(String),

    #[error("Invalid configuration: {0}")]
    ConfigError(String),

    #[error("Failed to format output: {0}")]
    FormatError(String),

    #[error("Failed to write output file: {0}")]
    OutputWriteError(#[from] std::io::Error),

    #[error("Repository detection failed: {0}")]
    RepositoryError(String),

    #[error("No journal files found")]
    NoJournalsFound,
}

pub type Result<T> = std::result::Result<T, JrnrvwError>;
```

### Error Handling Guidelines

1. **Use `Result` for all fallible operations**
2. **Provide context with `anyhow::Context`** for generic errors
3. **Use custom error types** via `thiserror` for domain-specific errors
4. **Fail fast** for unrecoverable errors (invalid config, missing required paths)
5. **Collect and report** for individual file failures (continue processing other files)
6. **Provide helpful messages** including file paths, line numbers where applicable

### Example Error Handling

```rust
impl Scanner {
    pub fn scan(&mut self, root: &Path) -> Result<Vec<JournalFile>> {
        if !root.exists() {
            return Err(JrnrvwError::ConfigError(
                format!("Root path does not exist: {}", root.display())
            ));
        }

        let entries = self.walker.walk(root)
            .context("Failed to walk directory tree")?;

        let mut journals = Vec::new();
        let mut errors = Vec::new();

        for entry in entries {
            match self.process_entry(&entry) {
                Ok(Some(journal)) => journals.push(journal),
                Ok(None) => {}, // Not a journal file
                Err(e) => {
                    // Collect error but continue
                    errors.push(e);
                }
            }
        }

        // Report errors if any
        if !errors.is_empty() {
            eprintln!("Warnings during scan:");
            for error in errors {
                eprintln!("  - {}", error);
            }
        }

        if journals.is_empty() {
            return Err(JrnrvwError::NoJournalsFound);
        }

        Ok(journals)
    }
}
```

---

## Performance Considerations

### Optimization Strategies

1. **Parallel File Processing**
   - Use `rayon` for parallel file reading and parsing
   - Process independent journal files concurrently

   ```rust
   use rayon::prelude::*;

   let entries: Vec<JournalEntry> = files
       .par_iter()
       .filter_map(|f| parser.parse(f).ok())
       .collect();
   ```

2. **Lazy Evaluation**
   - Only read file content when needed
   - Parse markdown on-demand

3. **Caching**
   - Cache repository detection results (already implemented)
   - Cache regex compilations (already implemented)

4. **Efficient Data Structures**
   - Use `HashMap` for O(1) lookups during grouping
   - Use `HashSet` for deduplication

5. **Memory Management**
   - Stream large files instead of loading entirely into memory
   - Limit content size in output (provide `--verbose` flag for full content)

6. **Early Termination**
   - Apply filters as early as possible
   - Skip parsing if file date is outside range

### Benchmarking

Create benchmarks for critical paths:

```rust
// benches/scanner_bench.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_scanner(c: &mut Criterion) {
    let config = ScanConfig::default();
    let scanner = Scanner::new(config);

    c.bench_function("scan 1000 files", |b| {
        b.iter(|| {
            scanner.scan(black_box(Path::new("tests/fixtures/large")))
        });
    });
}

criterion_group!(benches, bench_scanner);
criterion_main!(benches);
```

### Performance Targets

| Operation | Target | Notes |
|-----------|--------|-------|
| Scan 1000 files | < 100ms | Directory traversal |
| Parse 1000 journals | < 500ms | Markdown parsing |
| Group and analyze | < 100ms | In-memory operations |
| Format output (text) | < 50ms | Terminal output |
| End-to-end (1000 files) | < 1s | Total execution time |

---

## Security Considerations

### Threat Model

1. **Malicious Journal Files**
   - Extremely large files (DoS)
   - Binary files disguised as .md
   - Malformed markdown (parser exploits)

2. **File System Attacks**
   - Symlink attacks (directory traversal)
   - Permission bypass attempts

3. **Code Injection**
   - Shell commands in journal files (not executed)
   - Path traversal in filenames

### Security Measures

1. **File Size Limits**
   ```rust
   const MAX_FILE_SIZE: u64 = 10 * 1024 * 1024; // 10 MB

   fn read_journal_safe(path: &Path) -> Result<String> {
       let metadata = fs::metadata(path)?;
       if metadata.len() > MAX_FILE_SIZE {
           return Err(JrnrvwError::ConfigError(
               format!("File too large: {}", path.display())
           ));
       }
       fs::read_to_string(path)
   }
   ```

2. **Path Validation**
   ```rust
   fn validate_path(path: &Path) -> Result<()> {
       // Ensure path is canonical
       let canonical = path.canonicalize()
           .context("Failed to canonicalize path")?;

       // Ensure no path traversal
       if canonical.components().any(|c| c == Component::ParentDir) {
           return Err(JrnrvwError::ConfigError(
               "Path traversal detected".to_string()
           ));
       }

       Ok(())
   }
   ```

3. **No Code Execution**
   - Never execute shell commands found in journals
   - Never evaluate code blocks
   - Only extract and display text

4. **Symlink Handling**
   - Configure `walkdir` to not follow symlinks by default
   - Provide explicit flag if needed

5. **Input Validation**
   - Validate all CLI arguments
   - Sanitize file paths
   - Validate date formats

---

## Testing Strategy

### Unit Tests

Test individual components in isolation:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_date_extraction_valid() {
        let matcher = FileMatcher::new();
        let path = Path::new("2025.11.12 - JRN - test.md");
        let info = matcher.parse_journal_filename(path).unwrap();

        assert_eq!(info.date, NaiveDate::from_ymd(2025, 11, 12));
        assert_eq!(info.description, "test");
    }

    #[test]
    fn test_date_extraction_invalid() {
        let matcher = FileMatcher::new();
        let path = Path::new("invalid-format.md");
        assert!(matcher.parse_journal_filename(path).is_none());
    }

    #[test]
    fn test_github_task_extraction() {
        let extractor = TaskExtractor::new();
        let content = "Fixed #123 and #456";
        let events = vec![];
        let tasks = extractor.extract(content, &events);

        assert_eq!(tasks.len(), 2);
        assert_eq!(tasks[0].id, "#123");
        assert_eq!(tasks[1].id, "#456");
    }
}
```

### Integration Tests

Test module interactions:

```rust
// tests/integration/scanner_tests.rs
#[test]
fn test_scan_with_multiple_repos() {
    let temp_dir = create_test_fixture();
    let config = ScanConfig::default();
    let mut scanner = Scanner::new(config);

    let journals = scanner.scan(&temp_dir).unwrap();

    assert_eq!(journals.len(), 5);
    assert!(journals.iter().any(|j| j.repository.is_some()));
}

fn create_test_fixture() -> PathBuf {
    // Create temporary directory structure
    // with multiple repos and journal files
    todo!()
}
```

### End-to-End Tests

Test complete workflows:

```rust
#[test]
fn test_end_to_end_text_output() {
    let args = vec![
        "jrnrvw",
        "--path", "tests/fixtures/sample_repo",
        "--last-week",
        "--output", "text"
    ];

    let cli = Cli::parse_from(args);
    let executor = CommandExecutor::new(cli);
    let result = executor.execute();

    assert!(result.is_ok());
}
```

### Test Coverage Goals

- **Unit tests:** > 80% code coverage
- **Integration tests:** All module interactions
- **End-to-end tests:** All primary user workflows

### Test Fixtures

Create comprehensive test fixtures:

```
tests/fixtures/
├── simple/
│   ├── 2025.11.10 - JRN - day 1.md
│   └── 2025.11.11 - JRN - day 2.md
├── with_repos/
│   ├── repo_a/
│   │   ├── .git/
│   │   └── 2025.11.10 - JRN - work.md
│   └── repo_b/
│       ├── .git/
│       └── 2025.11.11 - JRN - more work.md
└── with_tasks/
    └── 2025.11.10 - JRN - fixed #123.md
```

---

## Implementation Roadmap

### Phase 1: Foundation (Week 1-2)

**Goal:** Core functionality working end-to-end

- [ ] Project setup (Cargo.toml, directory structure)
- [ ] CLI argument parsing with clap
- [ ] File scanner with walkdir
- [ ] Date extraction from filenames
- [ ] Repository detection
- [ ] Basic text output
- [ ] Initial tests

**Deliverable:** MVP that can find and list journal files

### Phase 2: Parsing & Analysis (Week 3-4)

**Goal:** Rich analysis capabilities

- [ ] Markdown parsing with pulldown-cmark
- [ ] Task identifier extraction (GitHub, JIRA, custom)
- [ ] Activity extraction
- [ ] Grouping by repository and task
- [ ] Date range filtering
- [ ] Summary statistics
- [ ] Enhanced tests

**Deliverable:** Full analysis with grouping and filtering

### Phase 3: Output Formats (Week 5)

**Goal:** Multiple output formats

- [ ] JSON output with serde
- [ ] Markdown report generation
- [ ] Colored terminal output
- [ ] Tree rendering
- [ ] Output formatting tests

**Deliverable:** Rich output options

### Phase 4: Polish & Optimization (Week 6)

**Goal:** Production-ready quality

- [ ] Parallel processing with rayon
- [ ] Performance benchmarks
- [ ] Error handling improvements
- [ ] Input validation
- [ ] Documentation (README, examples)
- [ ] Shell completions

**Deliverable:** Optimized, well-documented tool

### Phase 5: Advanced Features (Week 7+)

**Goal:** Nice-to-have enhancements

- [ ] Configuration file support
- [ ] Task pattern customization
- [ ] Search within journal content
- [ ] HTML output with templates
- [ ] Additional sort and filter options

**Deliverable:** Feature-complete tool

---

## Appendices

### A. Data Structure Reference

Complete data structure definitions:

```rust
// Journal file metadata
pub struct JournalFile {
    pub path: PathBuf,
    pub date: NaiveDate,
    pub description: String,
    pub repository: Option<Repository>,
}

// Parsed journal entry
pub struct JournalEntry {
    pub file: JournalFile,
    pub tasks: Vec<TaskReference>,
    pub activities: Vec<Activity>,
    pub content: String,
}

// Repository information
#[derive(Clone, Debug, Serialize)]
pub struct Repository {
    pub name: String,
    pub path: PathBuf,
    pub remote: Option<String>,
}

// Task reference
#[derive(Clone, Debug, Serialize)]
pub struct TaskReference {
    pub id: String,
    pub title: Option<String>,
    pub task_type: TaskType,
}

// Task type variants
#[derive(Clone, Debug, Serialize)]
pub enum TaskType {
    GitHub(u32),
    Jira(String),
    Custom(String),
    Heading(String),
}

// Activity entry
#[derive(Clone, Debug, Serialize)]
pub struct Activity {
    pub description: String,
    pub task: Option<String>,
}

// Date range
#[derive(Clone, Debug, Serialize)]
pub struct DateRange {
    pub from: NaiveDate,
    pub to: NaiveDate,
}

// Analysis result
#[derive(Debug, Serialize)]
pub struct AnalysisResult {
    pub repositories: Vec<RepositoryAnalysis>,
    pub summary: Summary,
}

// Repository analysis
#[derive(Debug, Serialize)]
pub struct RepositoryAnalysis {
    pub repository: Repository,
    pub task_groups: Vec<TaskGroup>,
    pub ungrouped: Vec<JournalEntry>,
}

// Task group
#[derive(Debug, Serialize)]
pub struct TaskGroup {
    pub task: TaskReference,
    pub journals: Vec<JournalEntry>,
}

// Summary statistics
#[derive(Debug, Serialize)]
pub struct Summary {
    pub date_range: DateRange,
    pub total_journals: usize,
    pub total_repositories: usize,
    pub total_tasks: usize,
    pub active_days: usize,
    pub most_active_day: Option<(NaiveDate, usize)>,
}
```

### B. Configuration Reference

```rust
pub struct Config {
    pub root_path: PathBuf,
    pub scan_config: ScanConfig,
    pub parse_config: ParseConfig,
    pub filter_config: FilterConfig,
    pub analyzer_config: AnalyzerConfig,
    pub output_format: OutputFormat,
    pub format_options: FormatOptions,
    pub output_file: Option<PathBuf>,
}

pub struct ScanConfig {
    pub max_depth: Option<usize>,
    pub follow_links: bool,
    pub include_hidden: bool,
}

pub struct ParseConfig {
    pub extract_tasks: bool,
    pub extract_activities: bool,
}

pub struct FilterConfig {
    pub date_range: Option<DateRange>,
    pub active_days_mode: bool,
    pub repo_filter: Option<String>,
    pub task_filter: Option<String>,
}

pub struct AnalyzerConfig {
    pub group_mode: GroupMode,
    pub merge_similar: bool,
    pub include_ungrouped: bool,
    pub sort_field: SortField,
    pub reverse_sort: bool,
    pub limit: Option<usize>,
}

pub struct FormatOptions {
    pub color_enabled: bool,
    pub show_paths: bool,
    pub verbose: bool,
    pub show_summary: bool,
}
```

### C. Cargo.toml

```toml
[package]
name = "jrnrvw"
version = "0.1.0"
edition = "2021"
authors = ["Your Name <email@example.com>"]
license = "MIT OR Apache-2.0"
description = "A CLI tool for analyzing task journal files"
repository = "https://github.com/yourusername/jrnrvw"
keywords = ["journal", "cli", "analysis", "productivity"]
categories = ["command-line-utilities"]

[dependencies]
clap = { version = "4.5", features = ["derive", "cargo"] }
chrono = { version = "0.4", features = ["serde"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
thiserror = "1.0"
walkdir = "2.5"
regex = "1.10"
pulldown-cmark = "0.12"
colored = "2.1"
itertools = "0.13"
rayon = "1.10"

[dev-dependencies]
criterion = "0.5"
tempfile = "3.10"
pretty_assertions = "1.4"

[[bench]]
name = "scanner_bench"
harness = false

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
```

### D. Example Output

**Example: Text Output**
```
Repository: experiment
├── Task: FEAT-123 - Authentication System
│   ├── 2025.11.10 - JRN - implemented jwt validation.md
│   │   • Implemented JWT token validation
│   │   • Added refresh token logic
│   └── 2025.11.12 - JRN - auth module review.md
│       • Code review feedback incorporated
└── Ungrouped Entries
    └── 2025.11.09 - JRN - weekly planning.md

Summary:
- Total Journals: 3
- Date Range: 2025.11.09 - 2025.11.12
- Repositories: 1
- Tasks: 1
- Active Days: 3
```

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025.11.12 | System Design | Initial HLD document |

---

**Next Steps:**
1. Review and approve this HLD
2. Set up project structure in `jrnrvw/` directory
3. Begin Phase 1 implementation
4. Create initial test fixtures
5. Implement core scanner and CLI modules

---

**End of Document**
