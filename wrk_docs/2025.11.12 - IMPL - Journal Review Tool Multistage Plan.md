# Multistage Implementation Plan: jrnrvw (Journal Review Tool)

**Document Type:** Implementation Plan (IMPL)
**Version:** 1.0
**Date:** 2025.11.12
**Author:** Implementation Planning
**Status:** Draft
**Related Documents:**
- 2025.11.12 - Journal Review Tool Specification.md
- 2025.11.12 - HLD - Journal Review Tool Implementation.md

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Implementation Philosophy](#implementation-philosophy)
3. [Stage Dependencies](#stage-dependencies)
4. [Detailed Stage Breakdown](#detailed-stage-breakdown)
5. [Risk Assessment & Mitigation](#risk-assessment--mitigation)
6. [Quality Gates](#quality-gates)
7. [Resource Requirements](#resource-requirements)
8. [Timeline & Milestones](#timeline--milestones)
9. [Testing Strategy by Stage](#testing-strategy-by-stage)
10. [Deployment & Release Plan](#deployment--release-plan)

---

## Executive Summary

This document provides a detailed, multistage implementation plan for the jrnrvw tool. The implementation is divided into **15 concrete stages** across **5 major phases**, with clear deliverables, dependencies, and success criteria for each stage.

**Total Estimated Duration:** 6-8 weeks
**Total Stages:** 15
**Major Phases:** 5
**Key Milestones:** 8

### Implementation Approach
- **Incremental:** Each stage produces working, testable code
- **Test-Driven:** Tests written alongside or before implementation
- **Iterative:** Early feedback loops with real-world usage
- **Quality-First:** Each stage includes quality gates

---

## Implementation Philosophy

### Core Principles

1. **Vertical Slicing:** Each stage delivers end-to-end functionality
2. **Fail Fast:** Issues are caught early through continuous testing
3. **Documentation as Code:** Code comments and examples are primary docs
4. **Real-World Testing:** Use on actual journal files from day 1
5. **Performance Awareness:** Profile and optimize throughout

### Development Standards

- **Code Coverage:** Minimum 80% per module
- **Documentation:** Every public API must have doc comments
- **Error Handling:** All errors must be properly typed and contextual
- **Performance:** All stages must meet defined performance targets
- **Security:** Security review at each stage

---

## Stage Dependencies

```
Stage 1.1: Project Setup
    â†“
Stage 1.2: CLI Foundation â”€â”€â”
    â†“                       â”‚
Stage 1.3: File Scanner  â†â”€â”€â”˜
    â†“
Stage 1.4: Date Extraction
    â†“
Stage 1.5: Basic Output
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MILESTONE 1: MVP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
Stage 2.1: Repository Detection
    â†“
Stage 2.2: Markdown Parser â”€â”€â”
    â†“                        â”‚
Stage 2.3: Task Extractor â†â”€â”€â”˜
    â†“
Stage 2.4: Grouping Engine
    â†“
Stage 2.5: Date Filtering
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MILESTONE 2: Core Analysis â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
Stage 3.1: JSON Output
    â†“
Stage 3.2: Markdown Reports
    â†“
Stage 3.3: Terminal Formatting
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MILESTONE 3: Output Formats â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
Stage 4.1: Error Handling
    â†“
Stage 4.2: Performance Optimization
    â†“
Stage 4.3: Documentation
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MILESTONE 4: Production Ready â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
Stage 5.1: Advanced Features
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MILESTONE 5: Feature Complete â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Detailed Stage Breakdown

## Phase 1: Foundation (Weeks 1-2)

**Goal:** Core functionality working end-to-end with basic features

---

### Stage 1.1: Project Setup and Scaffolding

**Duration:** 0.5 days
**Priority:** P0 (Critical)
**Dependencies:** None

#### Objectives
- Initialize Rust project with proper structure
- Configure dependencies
- Set up testing infrastructure
- Create initial documentation structure

#### Tasks

1. **Initialize Cargo Project** (30 min)
   ```bash
   cd jrnrvw
   cargo init --name jrnrvw
   ```
   - [ ] Run `cargo init`
   - [ ] Verify Cargo.toml created
   - [ ] Test with `cargo build`

2. **Configure Cargo.toml** (1 hour)
   - [ ] Add all dependencies from HLD
   - [ ] Configure dev-dependencies
   - [ ] Set up benchmark harness
   - [ ] Configure release profile
   ```toml
   [dependencies]
   clap = { version = "4.5", features = ["derive", "cargo"] }
   chrono = { version = "0.4", features = ["serde"] }
   serde = { version = "1.0", features = ["derive"] }
   serde_json = "1.0"
   anyhow = "1.0"
   thiserror = "1.0"
   walkdir = "2.5"
   regex = "1.10"
   pulldown-cmark = "0.12"
   colored = "2.1"
   itertools = "0.13"
   rayon = "1.10"
   ```

3. **Create Directory Structure** (30 min)
   - [ ] Create `src/cli/` module
   - [ ] Create `src/scanner/` module
   - [ ] Create `src/parser/` module
   - [ ] Create `src/analyzer/` module
   - [ ] Create `src/formatter/` module
   - [ ] Create `src/models/` module
   - [ ] Create `src/utils/` module
   - [ ] Create `tests/integration/` directory
   - [ ] Create `tests/fixtures/` directory
   - [ ] Create `benches/` directory

4. **Set Up Module Skeleton** (1 hour)
   - [ ] Create `mod.rs` for each module
   - [ ] Create `lib.rs` with module declarations
   - [ ] Create empty main.rs
   - [ ] Verify all modules compile

5. **Create Test Fixtures** (1 hour)
   - [ ] Create `tests/fixtures/simple/` with 2-3 sample journals
   - [ ] Create `tests/fixtures/with_repos/` with mock repositories
   - [ ] Create `tests/fixtures/with_tasks/` with task examples
   - [ ] Document fixture structure

6. **Initialize Documentation** (30 min)
   - [ ] Create README.md with project overview
   - [ ] Create CONTRIBUTING.md
   - [ ] Create LICENSE file (MIT/Apache-2.0)
   - [ ] Add doc comments template

#### Deliverables
- âœ… Compiling Rust project
- âœ… All module directories created
- âœ… Test fixtures available
- âœ… Basic documentation structure

#### Success Criteria
- [ ] `cargo build` succeeds
- [ ] `cargo test` runs (even with no tests)
- [ ] All modules compile without errors
- [ ] Test fixtures are readable and valid

#### Testing
- Unit: N/A (no logic yet)
- Integration: Verify project structure
- Manual: Build and check directory layout

---

### Stage 1.2: CLI Foundation with Clap

**Duration:** 1 day
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.1

#### Objectives
- Implement command-line argument parsing
- Define all CLI options and flags
- Add help generation and validation
- Create configuration builder

#### Tasks

1. **Define CLI Arguments** (2 hours)
   - [ ] Create `src/cli/args.rs`
   - [ ] Define `Cli` struct with clap derives
   - [ ] Define `DateFilter` argument group
   - [ ] Define `GroupingOptions` struct
   - [ ] Define `OutputOptions` struct
   - [ ] Add value enums (OutputFormat, GroupMode, SortField)
   - [ ] Add doc comments for all fields

2. **Implement Configuration Builder** (2 hours)
   - [ ] Create `src/models/config.rs`
   - [ ] Define `Config` struct
   - [ ] Implement `Config::from_cli()` method
   - [ ] Add validation logic
   - [ ] Handle default values

3. **Create Command Executor Skeleton** (2 hours)
   - [ ] Create `src/cli/commands.rs`
   - [ ] Define `CommandExecutor` struct
   - [ ] Implement `execute()` method skeleton
   - [ ] Add placeholder for each processing step

4. **Implement Main Entry Point** (1 hour)
   - [ ] Update `src/main.rs`
   - [ ] Parse CLI arguments
   - [ ] Create CommandExecutor
   - [ ] Call execute() and handle results
   - [ ] Add error display

5. **Add Help and Version** (30 min)
   - [ ] Configure help text
   - [ ] Add examples to help
   - [ ] Set version from Cargo.toml
   - [ ] Test help output

#### Deliverables
- âœ… Working CLI argument parsing
- âœ… Help text generation
- âœ… Configuration validation
- âœ… Main entry point

#### Success Criteria
- [ ] `jrnrvw --help` displays helpful information
- [ ] All argument combinations parse correctly
- [ ] Invalid arguments show clear error messages
- [ ] Configuration builds from CLI args

#### Testing
- Unit: Test config building with various arg combinations
- Integration: Test CLI parsing with clap's test helpers
- Manual: Run with various flags and verify help output

```rust
// Example test
#[test]
fn test_cli_parsing_basic() {
    let args = vec!["jrnrvw", "--path", "/tmp", "--last-week"];
    let cli = Cli::parse_from(args);
    assert_eq!(cli.path, Some(PathBuf::from("/tmp")));
    assert!(cli.date_filter.last_week);
}
```

---

### Stage 1.3: File System Scanner

**Duration:** 1.5 days
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.2

#### Objectives
- Implement directory walking
- Filter files efficiently
- Handle errors gracefully
- Optimize for large directory trees

#### Tasks

1. **Implement DirectoryWalker** (3 hours)
   - [ ] Create `src/scanner/walker.rs`
   - [ ] Define `ScanConfig` struct
   - [ ] Implement `DirectoryWalker::new()`
   - [ ] Implement `walk()` method using walkdir
   - [ ] Add depth limiting
   - [ ] Add hidden file filtering
   - [ ] Handle symlinks properly
   - [ ] Skip .git internals

2. **Add Error Handling** (2 hours)
   - [ ] Create `src/utils/error.rs`
   - [ ] Define `JrnrvwError` enum with thiserror
   - [ ] Add `ScanError` variant
   - [ ] Add `FileReadError` variant
   - [ ] Implement Display and Error traits
   - [ ] Add error context helpers

3. **Create Scanner Orchestrator** (2 hours)
   - [ ] Create `src/scanner/mod.rs`
   - [ ] Define `Scanner` struct
   - [ ] Implement `Scanner::new()`
   - [ ] Implement `scan()` method
   - [ ] Collect entries
   - [ ] Filter by file type
   - [ ] Return sorted results

4. **Write Tests** (3 hours)
   - [ ] Create `tests/scanner_tests.rs`
   - [ ] Test scanning empty directory
   - [ ] Test scanning with journals
   - [ ] Test max depth limiting
   - [ ] Test hidden file filtering
   - [ ] Test error conditions
   - [ ] Test with test fixtures

#### Deliverables
- âœ… Working directory scanner
- âœ… Error handling infrastructure
- âœ… Comprehensive tests
- âœ… Performance baseline

#### Success Criteria
- [ ] Scanner finds all journal files in fixtures
- [ ] Respects max depth setting
- [ ] Handles missing directories gracefully
- [ ] Scans 1000 files in < 100ms

#### Testing
- Unit: Test each component (walker, filter)
- Integration: Test scanner with fixtures
- Performance: Benchmark with large directory tree

```rust
#[test]
fn test_scanner_finds_journals() {
    let scanner = Scanner::new(ScanConfig::default());
    let results = scanner.scan(Path::new("tests/fixtures/simple")).unwrap();
    assert_eq!(results.len(), 2);
}
```

---

### Stage 1.4: Filename Date Extraction

**Duration:** 1 day
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.3

#### Objectives
- Parse journal filenames
- Extract date, description
- Validate date formats
- Handle edge cases

#### Tasks

1. **Implement FileMatcher** (3 hours)
   - [ ] Create `src/scanner/matcher.rs`
   - [ ] Define filename regex pattern
   - [ ] Implement `FileMatcher::new()`
   - [ ] Implement `is_journal_file()` method
   - [ ] Implement `parse_journal_filename()` method
   - [ ] Add date validation
   - [ ] Handle invalid dates

2. **Define JournalFile Model** (1 hour)
   - [ ] Create `src/models/journal.rs`
   - [ ] Define `JournalFile` struct
   - [ ] Add serde derives
   - [ ] Add helper methods
   - [ ] Add doc comments

3. **Integrate with Scanner** (2 hours)
   - [ ] Update Scanner to use FileMatcher
   - [ ] Parse filenames during scan
   - [ ] Filter non-matching files
   - [ ] Sort by date
   - [ ] Return JournalFile structs

4. **Write Tests** (2 hours)
   - [ ] Test valid filename formats
   - [ ] Test invalid formats
   - [ ] Test date validation
   - [ ] Test edge cases (leap years, etc.)
   - [ ] Test description extraction

#### Deliverables
- âœ… Filename parser
- âœ… JournalFile model
- âœ… Integration with scanner
- âœ… Comprehensive tests

#### Success Criteria
- [ ] Correctly parses "2025.11.12 - JRN - description.md"
- [ ] Rejects invalid date formats
- [ ] Rejects malformed filenames
- [ ] Extracts description correctly

#### Testing
- Unit: Test FileMatcher with various inputs
- Integration: Test scanner returns JournalFile objects
- Edge cases: Test invalid dates, formats

```rust
#[test]
fn test_parse_valid_filename() {
    let matcher = FileMatcher::new();
    let path = Path::new("2025.11.12 - JRN - test work.md");
    let info = matcher.parse_journal_filename(path).unwrap();

    assert_eq!(info.date, NaiveDate::from_ymd_opt(2025, 11, 12).unwrap());
    assert_eq!(info.description, "test work");
}

#[test]
fn test_parse_invalid_date() {
    let matcher = FileMatcher::new();
    let path = Path::new("2025.13.45 - JRN - invalid.md");
    assert!(matcher.parse_journal_filename(path).is_none());
}
```

---

### Stage 1.5: Basic Text Output

**Duration:** 1 day
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.4

#### Objectives
- Display journal files as simple list
- Show dates and descriptions
- Format output clearly
- Handle empty results

#### Tasks

1. **Create Simple Formatter** (2 hours)
   - [ ] Create `src/formatter/mod.rs`
   - [ ] Create `src/formatter/text.rs`
   - [ ] Define `TextFormatter` struct
   - [ ] Implement `format()` method
   - [ ] Format as simple list
   - [ ] Add date formatting

2. **Implement Presenter** (2 hours)
   - [ ] Create `src/cli/presenter.rs`
   - [ ] Define output interface
   - [ ] Handle stdout vs file output
   - [ ] Add error handling for write failures

3. **Wire Up End-to-End** (2 hours)
   - [ ] Update CommandExecutor::execute()
   - [ ] Call scanner
   - [ ] Format results
   - [ ] Output to terminal
   - [ ] Handle errors

4. **Test End-to-End** (2 hours)
   - [ ] Create integration test
   - [ ] Test with fixtures
   - [ ] Verify output format
   - [ ] Test error cases

#### Deliverables
- âœ… Working end-to-end MVP
- âœ… Simple text output
- âœ… Error handling
- âœ… Integration tests

#### Success Criteria
- [ ] Can scan and display journal files
- [ ] Output is clear and readable
- [ ] Handles empty directories
- [ ] Shows helpful error messages

#### Testing
- Unit: Test formatter output
- Integration: Test full pipeline
- Manual: Run on test fixtures and real journals

```bash
# Example output
$ jrnrvw --path tests/fixtures/simple

Found 2 journal entries:

2025.11.10 - test work
2025.11.11 - more testing

Total: 2 entries
```

---

### Phase 1 Milestone: MVP

**Deliverables:**
- âœ… CLI tool that scans directories
- âœ… Finds journal files by pattern
- âœ… Extracts dates from filenames
- âœ… Displays basic list output
- âœ… ~80% test coverage for implemented modules

**Success Criteria:**
- [ ] Tool runs without crashes
- [ ] Finds all test fixture journals
- [ ] Output is clear and correct
- [ ] All tests passing
- [ ] Performance meets targets

**Demo:**
```bash
# Run on actual journals
jrnrvw --path ~/work/journals

# Run on fixtures
jrnrvw --path tests/fixtures/with_repos
```

---

## Phase 2: Parsing & Analysis (Weeks 3-4)

**Goal:** Rich analysis with task extraction and grouping

---

### Stage 2.1: Repository Detection

**Duration:** 1 day
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.5

#### Objectives
- Detect .git repositories
- Extract repository metadata
- Cache detection results
- Handle nested repositories

#### Tasks

1. **Implement Repository Detector** (3 hours)
   - [ ] Create `src/scanner/repo_detector.rs`
   - [ ] Define `Repository` struct
   - [ ] Implement `RepositoryDetector::new()`
   - [ ] Implement `detect_repository()` method
   - [ ] Walk up directory tree to find .git
   - [ ] Cache results in HashMap
   - [ ] Extract repo name from directory

2. **Add Git Config Reading** (2 hours)
   - [ ] Read `.git/config` file
   - [ ] Parse remote URL (basic parsing)
   - [ ] Extract repo name from URL
   - [ ] Fall back to directory name
   - [ ] Handle errors gracefully

3. **Integrate with Scanner** (2 hours)
   - [ ] Update Scanner to use RepositoryDetector
   - [ ] Detect repo for each journal file
   - [ ] Store in JournalFile struct
   - [ ] Update tests

4. **Write Tests** (1 hour)
   - [ ] Test with mock .git directories
   - [ ] Test nested repos
   - [ ] Test files outside repos
   - [ ] Test caching behavior

#### Deliverables
- âœ… Repository detection
- âœ… Git config parsing
- âœ… Caching mechanism
- âœ… Tests

#### Success Criteria
- [ ] Detects repositories correctly
- [ ] Caches repeated lookups
- [ ] Handles missing .git gracefully
- [ ] Works with nested repos

#### Testing
- Unit: Test detector with mock directory structures
- Integration: Test scanner with repo fixtures
- Manual: Test with real repositories

---

### Stage 2.2: Markdown Parser

**Duration:** 1.5 days
**Priority:** P0 (Critical)
**Dependencies:** Stage 1.5

#### Objectives
- Parse markdown content
- Extract structure (headings, lists, paragraphs)
- Prepare for task extraction
- Handle malformed markdown

#### Tasks

1. **Create Markdown Parser** (3 hours)
   - [ ] Create `src/parser/markdown.rs`
   - [ ] Implement wrapper around pulldown-cmark
   - [ ] Parse markdown to event stream
   - [ ] Extract headings with levels
   - [ ] Extract list items
   - [ ] Extract paragraphs
   - [ ] Add error handling

2. **Define Parser Models** (2 hours)
   - [ ] Create `src/models/parsed_content.rs`
   - [ ] Define `ParsedMarkdown` struct
   - [ ] Define `Heading`, `ListItem`, `Paragraph` structs
   - [ ] Add traversal helpers
   - [ ] Add query methods

3. **Create Journal Parser** (3 hours)
   - [ ] Create `src/parser/journal.rs`
   - [ ] Define `JournalParser` struct
   - [ ] Implement `parse()` method
   - [ ] Read file content safely
   - [ ] Parse markdown
   - [ ] Create JournalEntry model
   - [ ] Add file size limits

4. **Write Tests** (3 hours)
   - [ ] Test with simple markdown
   - [ ] Test with complex markdown
   - [ ] Test with malformed content
   - [ ] Test with very large files
   - [ ] Test with empty files

#### Deliverables
- âœ… Markdown parsing
- âœ… Structured content extraction
- âœ… JournalEntry model
- âœ… Comprehensive tests

#### Success Criteria
- [ ] Parses test fixtures correctly
- [ ] Extracts structure properly
- [ ] Handles errors gracefully
- [ ] Respects file size limits

#### Testing
- Unit: Test markdown parsing
- Integration: Test journal parsing
- Performance: Test with large files

---

### Stage 2.3: Task Identifier Extraction

**Duration:** 2 days
**Priority:** P0 (Critical)
**Dependencies:** Stage 2.2

#### Objectives
- Extract GitHub issues (#123)
- Extract JIRA tickets (PROJ-123)
- Extract custom patterns
- Extract from headings
- Deduplicate tasks

#### Tasks

1. **Create Task Extractor** (4 hours)
   - [ ] Create `src/parser/task_extractor.rs`
   - [ ] Define `TaskExtractor` struct
   - [ ] Implement GitHub pattern matching
   - [ ] Implement JIRA pattern matching
   - [ ] Implement custom patterns
   - [ ] Implement heading extraction
   - [ ] Add deduplication logic

2. **Define Task Models** (2 hours)
   - [ ] Create `src/models/task.rs`
   - [ ] Define `TaskReference` struct
   - [ ] Define `TaskType` enum
   - [ ] Add helper methods
   - [ ] Add serialization

3. **Create Activity Extractor** (3 hours)
   - [ ] Create `src/parser/activity_extractor.rs`
   - [ ] Define `ActivityExtractor` struct
   - [ ] Extract from list items
   - [ ] Extract from paragraphs
   - [ ] Associate with tasks
   - [ ] Define `Activity` model

4. **Integrate with Parser** (2 hours)
   - [ ] Update JournalParser to extract tasks
   - [ ] Update JournalParser to extract activities
   - [ ] Store in JournalEntry
   - [ ] Update tests

5. **Write Tests** (3 hours)
   - [ ] Test GitHub issue extraction
   - [ ] Test JIRA ticket extraction
   - [ ] Test custom patterns
   - [ ] Test heading extraction
   - [ ] Test deduplication
   - [ ] Test activity extraction

#### Deliverables
- âœ… Task extraction
- âœ… Activity extraction
- âœ… Multiple pattern support
- âœ… Comprehensive tests

#### Success Criteria
- [ ] Extracts all task types correctly
- [ ] Deduplicates properly
- [ ] Associates activities with tasks
- [ ] Handles edge cases

#### Testing
- Unit: Test each extractor independently
- Integration: Test full parsing pipeline
- Fixtures: Create rich test fixtures with various task types

```rust
#[test]
fn test_github_issue_extraction() {
    let extractor = TaskExtractor::new();
    let content = "Fixed #123 and resolved #456";
    let events = vec![];
    let tasks = extractor.extract(content, &events);

    assert_eq!(tasks.len(), 2);
    assert_eq!(tasks[0].id, "#123");
    assert_eq!(tasks[1].id, "#456");
}
```

---

### Stage 2.4: Grouping Engine

**Duration:** 2 days
**Priority:** P0 (Critical)
**Dependencies:** Stage 2.3

#### Objectives
- Group journals by repository
- Group journals by task
- Support multiple grouping modes
- Compute statistics

#### Tasks

1. **Create Grouper** (4 hours)
   - [ ] Create `src/analyzer/grouper.rs`
   - [ ] Define `Grouper` struct
   - [ ] Implement `group_by_repo_and_task()`
   - [ ] Implement `group_by_repo()`
   - [ ] Implement `group_by_task()`
   - [ ] Implement `group_by_date()`
   - [ ] Handle ungrouped entries

2. **Define Analysis Models** (2 hours)
   - [ ] Create `src/models/analysis.rs`
   - [ ] Define `AnalysisResult` struct
   - [ ] Define `RepositoryAnalysis` struct
   - [ ] Define `TaskGroup` struct
   - [ ] Add serialization

3. **Create Statistics Calculator** (3 hours)
   - [ ] Create `src/analyzer/statistics.rs`
   - [ ] Define `Summary` struct
   - [ ] Compute total journals
   - [ ] Compute date range
   - [ ] Compute active days
   - [ ] Find most active day
   - [ ] Count repos and tasks

4. **Create Analyzer Orchestrator** (2 hours)
   - [ ] Create `src/analyzer/mod.rs`
   - [ ] Define `Analyzer` struct
   - [ ] Implement `analyze()` method
   - [ ] Coordinate grouping and stats
   - [ ] Return AnalysisResult

5. **Write Tests** (3 hours)
   - [ ] Test each grouping mode
   - [ ] Test with various data sets
   - [ ] Test statistics calculation
   - [ ] Test edge cases (empty, single entry)
   - [ ] Test ungrouped handling

#### Deliverables
- âœ… Grouping engine
- âœ… Statistics calculation
- âœ… Analysis models
- âœ… Comprehensive tests

#### Success Criteria
- [ ] Groups correctly by all modes
- [ ] Statistics are accurate
- [ ] Handles edge cases
- [ ] Performance is acceptable

#### Testing
- Unit: Test grouper and statistics independently
- Integration: Test analyzer with parsed data
- Fixtures: Use complex fixtures with multiple repos/tasks

---

### Stage 2.5: Date Range Filtering

**Duration:** 1.5 days
**Priority:** P1 (High)
**Dependencies:** Stage 2.4

#### Objectives
- Filter by date ranges
- Support predefined ranges (last week, etc.)
- Support custom ranges
- Support activity-based filtering

#### Tasks

1. **Create Filter** (4 hours)
   - [ ] Create `src/analyzer/filter.rs`
   - [ ] Define `Filter` struct
   - [ ] Define `FilterConfig` struct
   - [ ] Implement date range filtering
   - [ ] Implement last N days
   - [ ] Implement last N active days
   - [ ] Implement this week/month

2. **Add Date Utilities** (2 hours)
   - [ ] Create `src/utils/date.rs`
   - [ ] Add week start/end helpers
   - [ ] Add month start/end helpers
   - [ ] Add relative date helpers
   - [ ] Add date range validation

3. **Integrate with Analyzer** (2 hours)
   - [ ] Update Analyzer to apply filters
   - [ ] Filter before grouping
   - [ ] Update statistics to reflect filtering
   - [ ] Add filter info to output

4. **Write Tests** (3 hours)
   - [ ] Test each filter type
   - [ ] Test date range validation
   - [ ] Test edge cases (empty ranges, etc.)
   - [ ] Test activity-based filtering
   - [ ] Test with fixtures

#### Deliverables
- âœ… Date filtering
- âœ… Multiple filter modes
- âœ… Date utilities
- âœ… Tests

#### Success Criteria
- [ ] All filter modes work correctly
- [ ] Date calculations are accurate
- [ ] Invalid ranges are rejected
- [ ] Activity-based filtering is accurate

#### Testing
- Unit: Test filter and date utilities
- Integration: Test full analysis pipeline with filters
- Edge cases: Test boundary conditions

---

### Phase 2 Milestone: Core Analysis

**Deliverables:**
- âœ… Repository detection
- âœ… Task extraction
- âœ… Grouping by repo and task
- âœ… Date filtering
- âœ… Statistics calculation
- âœ… ~80% test coverage

**Success Criteria:**
- [ ] Analyzes real journals correctly
- [ ] Groups as specified
- [ ] Filters accurately
- [ ] Statistics are correct
- [ ] Performance meets targets

**Demo:**
```bash
# Show last week, grouped by repo and task
jrnrvw --path ~/work/journals --last-week

# Filter by repo
jrnrvw --path ~/work --repo experiment --last-month

# Show summary only
jrnrvw --path ~/work --summary
```

---

## Phase 3: Output Formats (Week 5)

**Goal:** Multiple output formats with rich formatting

---

### Stage 3.1: JSON Output

**Duration:** 1 day
**Priority:** P1 (High)
**Dependencies:** Stage 2.5

#### Objectives
- Serialize to JSON
- Pretty print JSON
- Support piping to other tools
- Validate JSON structure

#### Tasks

1. **Create JSON Formatter** (2 hours)
   - [ ] Create `src/formatter/json.rs`
   - [ ] Define `JsonFormatter` struct
   - [ ] Implement `format()` method
   - [ ] Use serde_json for serialization
   - [ ] Add pretty printing
   - [ ] Handle serialization errors

2. **Add Serde Derives** (2 hours)
   - [ ] Add serde derives to all models
   - [ ] Add custom serializers where needed
   - [ ] Handle optional fields
   - [ ] Handle date serialization
   - [ ] Test serialization

3. **Create Formatter Factory** (2 hours)
   - [ ] Create `src/formatter/factory.rs`
   - [ ] Define `FormatterFactory`
   - [ ] Create method to select formatter
   - [ ] Return trait object or enum
   - [ ] Handle all output formats

4. **Write Tests** (2 hours)
   - [ ] Test JSON serialization
   - [ ] Validate JSON structure
   - [ ] Test with various analysis results
   - [ ] Test error handling

#### Deliverables
- âœ… JSON output
- âœ… Formatter factory
- âœ… Serde integration
- âœ… Tests

#### Success Criteria
- [ ] Outputs valid JSON
- [ ] JSON is well-structured
- [ ] Can be parsed by jq
- [ ] Includes all data

#### Testing
- Unit: Test JSON formatter
- Integration: Test with full analysis
- Manual: Validate with jq

```bash
# Test JSON output
jrnrvw --path tests/fixtures --output json | jq .
```

---

### Stage 3.2: Markdown Report Generation

**Duration:** 1.5 days
**Priority:** P2 (Medium)
**Dependencies:** Stage 3.1

#### Objectives
- Generate markdown reports
- Format with proper structure
- Include tables for statistics
- Support GitHub-flavored markdown

#### Tasks

1. **Create Markdown Formatter** (4 hours)
   - [ ] Create `src/formatter/markdown.rs`
   - [ ] Define `MarkdownFormatter` struct
   - [ ] Implement `format()` method
   - [ ] Generate headings for repos
   - [ ] Generate lists for tasks
   - [ ] Generate tables for statistics
   - [ ] Add proper escaping

2. **Create Report Template** (2 hours)
   - [ ] Design report structure
   - [ ] Add summary section
   - [ ] Add details section
   - [ ] Add date range info
   - [ ] Add metadata

3. **Add File Output** (2 hours)
   - [ ] Update CLI to support --file option
   - [ ] Write output to file
   - [ ] Handle file errors
   - [ ] Support stdout redirection

4. **Write Tests** (2 hours)
   - [ ] Test markdown generation
   - [ ] Validate markdown structure
   - [ ] Test with various data
   - [ ] Test file writing

#### Deliverables
- âœ… Markdown output
- âœ… File output support
- âœ… Report template
- âœ… Tests

#### Success Criteria
- [ ] Generates valid markdown
- [ ] Reports are readable
- [ ] Renders well in GitHub
- [ ] Statistics are formatted nicely

#### Testing
- Unit: Test markdown formatter
- Integration: Test with full pipeline
- Manual: View in markdown renderer

---

### Stage 3.3: Enhanced Terminal Formatting

**Duration:** 1.5 days
**Priority:** P1 (High)
**Dependencies:** Stage 3.2

#### Objectives
- Add colors to terminal output
- Create tree structure rendering
- Improve readability
- Support --no-color flag

#### Tasks

1. **Update Text Formatter** (3 hours)
   - [ ] Update `src/formatter/text.rs`
   - [ ] Add colored dependency
   - [ ] Colorize dates (green)
   - [ ] Colorize repos (cyan)
   - [ ] Colorize tasks (yellow)
   - [ ] Add color toggle

2. **Create Tree Renderer** (4 hours)
   - [ ] Create `src/formatter/tree_renderer.rs`
   - [ ] Implement tree drawing
   - [ ] Use box-drawing characters
   - [ ] Handle nested structure
   - [ ] Handle last-child branches
   - [ ] Add proper indentation

3. **Enhance Summary Display** (2 hours)
   - [ ] Format summary section
   - [ ] Add visual separators
   - [ ] Add statistics boxes
   - [ ] Improve layout

4. **Write Tests** (2 hours)
   - [ ] Test tree rendering
   - [ ] Test color output
   - [ ] Test no-color mode
   - [ ] Test summary formatting

#### Deliverables
- âœ… Colored output
- âœ… Tree structure
- âœ… Enhanced summary
- âœ… Tests

#### Success Criteria
- [ ] Output is visually appealing
- [ ] Colors improve readability
- [ ] Tree structure is clear
- [ ] Works without color

#### Testing
- Unit: Test tree renderer
- Integration: Test full formatting
- Manual: Review terminal output

---

### Phase 3 Milestone: Output Formats

**Deliverables:**
- âœ… JSON output
- âœ… Markdown reports
- âœ… Enhanced terminal output
- âœ… File output support
- âœ… Colored output

**Success Criteria:**
- [ ] All output formats work
- [ ] Outputs are well-formatted
- [ ] Data is complete and accurate
- [ ] Performance is acceptable

**Demo:**
```bash
# JSON output
jrnrvw --output json | jq .

# Markdown report
jrnrvw --output markdown --file report.md

# Colored terminal
jrnrvw --last-week

# No color
jrnrvw --last-week --no-color
```

---

## Phase 4: Production Ready (Week 6)

**Goal:** Polish, optimize, and document for production use

---

### Stage 4.1: Comprehensive Error Handling

**Duration:** 1.5 days
**Priority:** P0 (Critical)
**Dependencies:** Stage 3.3

#### Objectives
- Improve all error messages
- Add context to errors
- Handle edge cases
- Provide helpful suggestions

#### Tasks

1. **Enhance Error Types** (3 hours)
   - [ ] Update `src/utils/error.rs`
   - [ ] Add more specific error variants
   - [ ] Add context fields
   - [ ] Improve error messages
   - [ ] Add suggestions

2. **Add Error Context** (3 hours)
   - [ ] Use anyhow::Context throughout
   - [ ] Add file paths to errors
   - [ ] Add line numbers where relevant
   - [ ] Add helpful hints

3. **Improve Error Display** (2 hours)
   - [ ] Format errors nicely
   - [ ] Add colors to error output
   - [ ] Group related errors
   - [ ] Show stack trace in verbose mode

4. **Handle Edge Cases** (3 hours)
   - [ ] Empty directories
   - [ ] Permission denied
   - [ ] Large files
   - [ ] Invalid encodings
   - [ ] Symlink loops

5. **Write Tests** (2 hours)
   - [ ] Test all error paths
   - [ ] Test error messages
   - [ ] Test error context
   - [ ] Test suggestions

#### Deliverables
- âœ… Enhanced error handling
- âœ… Helpful error messages
- âœ… Edge case handling
- âœ… Tests

#### Success Criteria
- [ ] Errors are clear and actionable
- [ ] Edge cases don't cause panics
- [ ] Suggestions are helpful
- [ ] Debugging is easier

#### Testing
- Unit: Test error creation and display
- Integration: Test error propagation
- Manual: Trigger various errors and review messages

---

### Stage 4.2: Performance Optimization

**Duration:** 2 days
**Priority:** P1 (High)
**Dependencies:** Stage 4.1

#### Objectives
- Optimize critical paths
- Add parallel processing
- Reduce memory usage
- Meet performance targets

#### Tasks

1. **Profile Performance** (3 hours)
   - [ ] Set up criterion benchmarks
   - [ ] Benchmark scanner
   - [ ] Benchmark parser
   - [ ] Benchmark analyzer
   - [ ] Identify bottlenecks

2. **Add Parallel Processing** (4 hours)
   - [ ] Add rayon dependency
   - [ ] Parallelize file parsing
   - [ ] Parallelize task extraction
   - [ ] Measure improvements
   - [ ] Handle thread safety

3. **Optimize Memory Usage** (3 hours)
   - [ ] Profile memory usage
   - [ ] Use string interning for common strings
   - [ ] Optimize data structures
   - [ ] Stream large files
   - [ ] Reduce allocations

4. **Optimize Algorithms** (3 hours)
   - [ ] Improve grouping algorithm
   - [ ] Cache regex compilations (already done)
   - [ ] Optimize filtering
   - [ ] Use better data structures

5. **Benchmark and Validate** (3 hours)
   - [ ] Run benchmarks
   - [ ] Compare to targets
   - [ ] Create large test fixtures
   - [ ] Validate performance improvements
   - [ ] Document results

#### Deliverables
- âœ… Parallel processing
- âœ… Performance benchmarks
- âœ… Optimization report
- âœ… Performance tests

#### Success Criteria
- [ ] Scan 1000 files < 100ms
- [ ] Parse 1000 journals < 500ms
- [ ] End-to-end < 1s for 1000 files
- [ ] Memory usage is reasonable

#### Testing
- Performance: Run criterion benchmarks
- Scale: Test with large datasets
- Regression: Ensure no performance regressions

---

### Stage 4.3: Documentation and Examples

**Duration:** 2 days
**Priority:** P1 (High)
**Dependencies:** Stage 4.2

#### Objectives
- Complete README
- Add usage examples
- Document all public APIs
- Create contributor guide

#### Tasks

1. **Complete README** (4 hours)
   - [ ] Add project description
   - [ ] Add installation instructions
   - [ ] Add usage examples
   - [ ] Add features list
   - [ ] Add screenshots/examples
   - [ ] Add badges
   - [ ] Add contributing section

2. **Write API Documentation** (4 hours)
   - [ ] Add doc comments to all public items
   - [ ] Add examples to doc comments
   - [ ] Document error types
   - [ ] Document configuration
   - [ ] Generate docs with `cargo doc`

3. **Create Examples** (3 hours)
   - [ ] Create `examples/` directory
   - [ ] Add basic usage example
   - [ ] Add filtering example
   - [ ] Add output format example
   - [ ] Add library usage example

4. **Write Contributor Guide** (2 hours)
   - [ ] Update CONTRIBUTING.md
   - [ ] Add development setup
   - [ ] Add testing guidelines
   - [ ] Add code style guide
   - [ ] Add PR process

5. **Add Shell Completions** (3 hours)
   - [ ] Generate bash completions
   - [ ] Generate zsh completions
   - [ ] Generate fish completions
   - [ ] Add installation instructions
   - [ ] Test completions

#### Deliverables
- âœ… Complete README
- âœ… API documentation
- âœ… Usage examples
- âœ… Contributor guide
- âœ… Shell completions

#### Success Criteria
- [ ] README is comprehensive
- [ ] API docs are complete
- [ ] Examples work correctly
- [ ] Completions work in all shells

#### Testing
- Manual: Review all documentation
- Integration: Test all examples
- Manual: Test shell completions

---

### Phase 4 Milestone: Production Ready

**Deliverables:**
- âœ… Comprehensive error handling
- âœ… Performance optimization
- âœ… Complete documentation
- âœ… Shell completions
- âœ… >80% test coverage

**Success Criteria:**
- [ ] Ready for real-world use
- [ ] Performance targets met
- [ ] Documentation is complete
- [ ] All tests passing
- [ ] No known critical bugs

**Release:**
- [ ] Tag v0.1.0
- [ ] Create GitHub release
- [ ] Publish to crates.io (optional)
- [ ] Announce release

---

## Phase 5: Advanced Features (Week 7+)

**Goal:** Nice-to-have enhancements and polish

---

### Stage 5.1: Advanced Features

**Duration:** Ongoing
**Priority:** P2-P3 (Medium-Low)
**Dependencies:** Stage 4.3

#### Feature List

1. **Configuration File Support** (2 days)
   - [ ] Define config file format (TOML/YAML)
   - [ ] Add config file parsing
   - [ ] Support custom task patterns
   - [ ] Support default options
   - [ ] Document configuration

2. **Content Search** (2 days)
   - [ ] Add --search flag
   - [ ] Search journal content
   - [ ] Support regex search
   - [ ] Highlight matches
   - [ ] Filter by search results

3. **HTML Output** (2 days)
   - [ ] Create HTML template
   - [ ] Add CSS styling
   - [ ] Generate static HTML
   - [ ] Support themes
   - [ ] Add interactivity

4. **Advanced Sorting** (1 day)
   - [ ] Sort by activity count
   - [ ] Sort by last modified
   - [ ] Multi-level sorting
   - [ ] Reverse sorting

5. **Task Merging** (1 day)
   - [ ] Detect similar tasks
   - [ ] Merge task groups
   - [ ] Configure similarity threshold
   - [ ] Add manual override

6. **Export Formats** (1 day)
   - [ ] CSV export
   - [ ] Excel export
   - [ ] Calendar format (iCal)
   - [ ] Timeline view

#### Prioritization

Features should be prioritized based on:
- User feedback
- Usage patterns
- Development effort
- Value proposition

---

## Risk Assessment & Mitigation

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Performance issues with large datasets | Medium | High | Early benchmarking, parallel processing |
| Markdown parsing edge cases | High | Medium | Comprehensive test fixtures, fuzzing |
| Repository detection failures | Low | Medium | Fallback to directory names, error handling |
| Date parsing ambiguities | Low | Low | Strict format, clear documentation |
| Memory usage with large files | Medium | Medium | File size limits, streaming |

### Process Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Feature creep | Medium | Medium | Strict phase boundaries, MVP focus |
| Testing gaps | Medium | High | Coverage requirements, code review |
| Documentation lag | High | Medium | Document as you code, dedicated stage |
| Burnout from long project | Medium | High | Regular breaks, realistic timeline |

### Mitigation Strategies

1. **Early Testing:** Test each stage thoroughly before moving on
2. **Real-World Usage:** Use on actual journals throughout development
3. **Regular Reviews:** Review code and design after each phase
4. **Performance Monitoring:** Benchmark regularly, not just at the end
5. **User Feedback:** Get feedback early and often
6. **Incremental Delivery:** Ship MVP early, iterate based on feedback

---

## Quality Gates

Each stage must pass these quality gates before proceeding:

### Code Quality
- [ ] All code compiles without warnings
- [ ] Clippy passes with no warnings
- [ ] Code is formatted with rustfmt
- [ ] No TODO comments in mainline code
- [ ] All public APIs have doc comments

### Testing Quality
- [ ] Unit tests cover critical paths
- [ ] Integration tests pass
- [ ] Code coverage > 80% for new code
- [ ] Manual testing completed
- [ ] Edge cases tested

### Documentation Quality
- [ ] README is up-to-date
- [ ] API docs are complete
- [ ] Examples work correctly
- [ ] CHANGELOG is updated
- [ ] Commit messages are clear

### Performance Quality
- [ ] Benchmarks pass
- [ ] No performance regressions
- [ ] Memory usage is acceptable
- [ ] Meets stage-specific targets

### Security Quality
- [ ] No unsafe code without justification
- [ ] Input validation in place
- [ ] Error messages don't leak sensitive info
- [ ] File size limits enforced
- [ ] Path traversal prevented

---

## Resource Requirements

### Development Environment
- Rust toolchain (stable)
- IDE with rust-analyzer
- Git
- Development journals for testing

### Testing Infrastructure
- Test fixture generation
- Benchmarking setup
- CI/CD (GitHub Actions)
- Code coverage tools

### Documentation Tools
- cargo-doc
- mdbook (optional)
- Shell completion generators

### Time Allocation

| Phase | Duration | Effort (hrs) |
|-------|----------|--------------|
| Phase 1 | 2 weeks | 60-80 |
| Phase 2 | 2 weeks | 60-80 |
| Phase 3 | 1 week | 30-40 |
| Phase 4 | 1 week | 30-40 |
| Phase 5 | Ongoing | Variable |
| **Total** | **6-8 weeks** | **180-240** |

---

## Timeline & Milestones

### Gantt Chart Overview

```
Week 1-2: Phase 1 - Foundation
â”œâ”€â”€ Stage 1.1: Project Setup (Day 1)
â”œâ”€â”€ Stage 1.2: CLI Foundation (Day 2)
â”œâ”€â”€ Stage 1.3: File Scanner (Day 3-4)
â”œâ”€â”€ Stage 1.4: Date Extraction (Day 5-6)
â””â”€â”€ Stage 1.5: Basic Output (Day 7-8)
    â””â”€â”€ MILESTONE 1: MVP âœ“

Week 3-4: Phase 2 - Parsing & Analysis
â”œâ”€â”€ Stage 2.1: Repository Detection (Day 9-10)
â”œâ”€â”€ Stage 2.2: Markdown Parser (Day 11-12)
â”œâ”€â”€ Stage 2.3: Task Extraction (Day 13-15)
â”œâ”€â”€ Stage 2.4: Grouping Engine (Day 16-18)
â””â”€â”€ Stage 2.5: Date Filtering (Day 19-20)
    â””â”€â”€ MILESTONE 2: Core Analysis âœ“

Week 5: Phase 3 - Output Formats
â”œâ”€â”€ Stage 3.1: JSON Output (Day 21-22)
â”œâ”€â”€ Stage 3.2: Markdown Reports (Day 23-24)
â””â”€â”€ Stage 3.3: Terminal Formatting (Day 25-26)
    â””â”€â”€ MILESTONE 3: Output Formats âœ“

Week 6: Phase 4 - Production Ready
â”œâ”€â”€ Stage 4.1: Error Handling (Day 27-28)
â”œâ”€â”€ Stage 4.2: Performance (Day 29-31)
â””â”€â”€ Stage 4.3: Documentation (Day 32-34)
    â””â”€â”€ MILESTONE 4: Production Ready âœ“
    â””â”€â”€ RELEASE: v0.1.0 ğŸš€

Week 7+: Phase 5 - Advanced Features
â””â”€â”€ Stage 5.1: Advanced Features (Ongoing)
    â””â”€â”€ MILESTONE 5: Feature Complete âœ“
```

### Key Milestones

1. **Milestone 1: MVP** (End of Week 2)
   - Basic scanning and output
   - ~20% of final functionality
   - First real-world testing

2. **Milestone 2: Core Analysis** (End of Week 4)
   - Full analysis pipeline
   - ~60% of final functionality
   - Useful for daily use

3. **Milestone 3: Output Formats** (End of Week 5)
   - Multiple output formats
   - ~80% of final functionality
   - Ready for broader testing

4. **Milestone 4: Production Ready** (End of Week 6)
   - Polished and documented
   - 100% of planned functionality
   - Ready for release

5. **Milestone 5: Feature Complete** (Week 7+)
   - All nice-to-have features
   - Future enhancements
   - Ongoing maintenance

---

## Testing Strategy by Stage

### Unit Testing

Each stage includes unit tests for:
- Core algorithms
- Data transformations
- Edge cases
- Error conditions

**Coverage Target:** >80% per module

### Integration Testing

Integration tests verify:
- Module interactions
- End-to-end flows
- Configuration handling
- Error propagation

**Test Fixtures:**
- Simple: 2-3 journals, no repos
- With Repos: Multiple repos, nested structure
- With Tasks: Various task types
- Complex: Real-world scenarios
- Large: Performance testing (1000+ journals)

### Performance Testing

Benchmarks for:
- File scanning
- Markdown parsing
- Task extraction
- Grouping and analysis
- Output formatting
- End-to-end pipeline

**Tools:** criterion.rs

### Manual Testing

Each phase includes manual testing:
- CLI usability
- Output formatting
- Error messages
- Performance feel
- Real-world usage

---

## Deployment & Release Plan

### Pre-Release Checklist

- [ ] All tests passing
- [ ] Benchmarks meet targets
- [ ] Documentation complete
- [ ] No critical bugs
- [ ] Security review done
- [ ] License files present
- [ ] CHANGELOG updated
- [ ] Version bumped

### Release Process

1. **Tag Release**
   ```bash
   git tag -a v0.1.0 -m "Release v0.1.0"
   git push origin v0.1.0
   ```

2. **Build Release Binaries**
   ```bash
   cargo build --release
   ```

3. **Create GitHub Release**
   - Upload binaries
   - Include CHANGELOG
   - Add installation instructions

4. **Publish to crates.io** (Optional)
   ```bash
   cargo publish
   ```

5. **Announce Release**
   - GitHub Discussions
   - Social media
   - Relevant communities

### Post-Release

- [ ] Monitor for issues
- [ ] Respond to feedback
- [ ] Plan next iteration
- [ ] Update roadmap

---

## Appendix: Quick Reference

### Stage Summary Table

| Stage | Phase | Duration | Priority | Dependencies | Key Deliverables |
|-------|-------|----------|----------|--------------|------------------|
| 1.1 | 1 | 0.5d | P0 | None | Project setup |
| 1.2 | 1 | 1d | P0 | 1.1 | CLI parsing |
| 1.3 | 1 | 1.5d | P0 | 1.2 | File scanner |
| 1.4 | 1 | 1d | P0 | 1.3 | Date extraction |
| 1.5 | 1 | 1d | P0 | 1.4 | Basic output |
| 2.1 | 2 | 1d | P0 | 1.5 | Repo detection |
| 2.2 | 2 | 1.5d | P0 | 1.5 | Markdown parser |
| 2.3 | 2 | 2d | P0 | 2.2 | Task extraction |
| 2.4 | 2 | 2d | P0 | 2.3 | Grouping |
| 2.5 | 2 | 1.5d | P1 | 2.4 | Date filtering |
| 3.1 | 3 | 1d | P1 | 2.5 | JSON output |
| 3.2 | 3 | 1.5d | P2 | 3.1 | Markdown reports |
| 3.3 | 3 | 1.5d | P1 | 3.2 | Terminal formatting |
| 4.1 | 4 | 1.5d | P0 | 3.3 | Error handling |
| 4.2 | 4 | 2d | P1 | 4.1 | Performance |
| 4.3 | 4 | 2d | P1 | 4.2 | Documentation |
| 5.1 | 5 | Ongoing | P2-P3 | 4.3 | Advanced features |

### Command Reference

```bash
# Development
cargo build
cargo test
cargo clippy
cargo fmt
cargo doc --open

# Benchmarking
cargo bench

# Testing
cargo test --all
cargo test --test integration_tests

# Release
cargo build --release
cargo publish
```

### File Structure Reference

```
jrnrvw/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs
â”‚   â”œâ”€â”€ lib.rs
â”‚   â”œâ”€â”€ cli/          # Stage 1.2
â”‚   â”œâ”€â”€ scanner/      # Stage 1.3, 1.4, 2.1
â”‚   â”œâ”€â”€ parser/       # Stage 2.2, 2.3
â”‚   â”œâ”€â”€ analyzer/     # Stage 2.4, 2.5
â”‚   â”œâ”€â”€ formatter/    # Stage 1.5, 3.1, 3.2, 3.3
â”‚   â”œâ”€â”€ models/       # Throughout
â”‚   â””â”€â”€ utils/        # Throughout
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”œâ”€â”€ benches/          # Stage 4.2
â”œâ”€â”€ examples/         # Stage 4.3
â””â”€â”€ docs/             # Stage 4.3
```

---

## Document Change Log

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025.11.12 | Implementation Planning | Initial multistage implementation plan |

---

**END OF DOCUMENT**

This implementation plan provides a detailed, actionable roadmap for building the jrnrvw tool. Each stage is designed to be completable in 0.5-2 days with clear objectives, tasks, deliverables, and success criteria. The plan emphasizes quality, testing, and incremental delivery to ensure a successful implementation.
